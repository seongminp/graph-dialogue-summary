but we have in a point that everything is more or less the similar more or less similar .
OK , but that 's a That is a good check point ,
, it 's pretty funny looking .
it they probably have some fi particular s fixed point arithmetic that they 're using ,
that they 're s probably working with fixed point or integer .
, given at the level you 're doing things in floating point on the computer , I don't think it matters , would be my ,
and hopefully there should be some point at which having more information doesn't tell you really all that much more about what the phones are .
that 's That 's a pretty good point right there .
So probably it should be something we should try then is to is to see if is at some point just to take i to transform the data
That 's that 's , that 's true .

And the other three features are R , the variance of the difference between the two spectrum ,
Ye - that 's the variance ,
So the particular measure that she chose was the variance of this m of this difference ,
maybe there 's something about the variance that 's that 's not enough
, why they chose sixty - four and something else , that was probably just experimental .

and it 's still it 's still a reasonable forum for students to present things .
, it 's for engineering students of any kind , it 's it 's if you haven't been there much , it 's good to go to ,
and so if you if you give it less data it still does a reasonable job in learning the patterns .
Actually one percent is , in a reasonable range .

and figure out what they can what they most need from things , and that 's what they 're good at .
, another way , saying let it figure out what 's the what is the interaction ,
because I was figuring you have it turned back so far that it

TIMIT canonical ma mappings .
and made a mapping from the MFCC 's to these phonological features ,
I 'm just doing detection of phonological features .
and I was like , " , this is Is the mapping from N to this phonological feature called " coronal " ,
to come up with a mapping from MFCC 's or s some feature set , to w to whether there 's existence of a particular phonological feature .
it 's to learn a mapping from the MFCC 's to phonological features .
I 'm not I 'm not planning to do any phoneme mapping yet .
and this i their idea was to first find a mapping from MFCC 's to phonological features
and then later on , once you have these phonological features , then map that to phones .

So if it 's if it 's if it 's low energy but the but the spectrum looks like that or like that , it 's probably silence .
but if it 's low energy and the spectrum looks like that , it 's probably unvoiced .
or i you 'd have some other energy measure
I why they have some constant in the expression of the lower energy .
And this smooths it for very small energies .

We have noisy TIMIT with the noise of the TI - digits .
And now we have another noisy TIMIT also with the noise of Italian database .
there 's gonna be it looks like there 's gonna be a noisy some large vocabulary noisy too .
So it 's a little more noise robust .
, and that 's that 's why when people started getting databases that had a little more noise in it , like Broadcast News and so on ,

and then he 's here for a couple days before he goes to Salt Lake City .
If you just do this by counting , then you should be able to find out in a pretty straightforward way whether you have a sufficient set of events to do the level of classification of phones that you 'd like .
But that 's looking at it for classification for binary classification ,
and it 's just not going to affect phonetic classification .

cuz that 'd be pretty simple
, it 'd be on the simple side ,
. The idea is with a with a very simple statistical structure , could you could you at least verify that you 've chosen features that are sufficient .
Just it 's it 's it 's really simple , a detection of phonological features .

, nearest - neighbor good is good if you have lots and lots of examples .
but if you have lots and lots of examples , then it can take a while to use nearest - neighbor .
There 's lots of look ups .
There 's lots of little differences .

so here 's here 's an idea .
And the the constant in front of it , I have no idea .
, you could even then to get an idea about how different it is , you could maybe take some subset and , go through a few sentences , mark them by hand
just to get an idea a rough idea of h if it really even makes a difference .
, so I the idea to this is that it is reputed to be somewhat better in that regard .

I 'm saying that 's what people us typically use .
like in the old days people did like zero crossing counts .
So he 's he 's going to ICASSP which is good .
Do have Have people stopped going to ICASSP in recent years ?
, people are less consistent about going to ICASSP
But I if people have done careful comparisons of this on large tasks or anything .
And some people have claimed that they got some better performance doing that ,

the new base system the new base system .
the Aurora system with the new filter , VAD like that .
So you 're you 're trying to be clever and say what 's the statistic that should we should get about this difference
Some some read task actually , that they 're preparing .
So y you 're restricted to being positive .
I , I 'm not what you what you 're what you get out of your system .
And his the way that the S R I system looks like it works is that it reads the wavefiles directly ,
So you 're so you have a system which for one reason or another is relatively poor ,
, w we 're often asked this when we work with a system that isn't isn't industry standard great ,
, this other one 's it was a pretty good system .

See , because it because this is this is just like a single number to tell you " does the spectrum look like that or does it look like that " .
That I look in the with the other nnn the other MLP that we have are more or less the same number .
and you can s you can specify a different number of features different number of filters ,
So that 's a way that you change what the what the bandwidth is .
Y you can't do it without changing the number of filters ,

And also , just working on my final project for Jordan 's class ,
OK , and you were saying something starting to say something else about your class project , or ?
and then it finds the optimal separating plane , between these two different classes ,
wh I 'm what is the task for the class project ?
That 's probably not what he 's going to do on his class project .

So we talked on the phone about this , that there was still a difference of a of a few percent
and you told me that there was a difference in how the normalization was done .
because the difference in performance is it 's not gigantic
but that the normalization difference was one of the possibilities ,
I I don't think that the normalization difference is gonna account for everything .
Although really , , a couple three percent difference in word error rate could easily come from some difference in normalization , I would think .
, there 's other small differences
the fundamental d difference that we 've seen any difference from before , which is actually an advantage for the P L P i , , is that the smoothing at the end is auto - regressive instead of being cepstral , from cepstral truncation .

I 'm adding complexity .
Cuz it was getting like one percent So it 's still this ratio .
O one thing I 'm wondering about is what this mean subtraction method will do if it 's faced with additive noise .
Cuz I it 's cuz I what log magnitude spectral subtraction is gonna do to additive noise .
but but you 've already seen that cuz there is added noise here .

So in your in the thing that you 're doing , you have a vector of ones and zeros for each phone ?
f so for every phone there is there is a a vector of ones and zeros f corresponding to whether it exhibits a particular phonological feature or not .
or to come up with these vectors to see how closely they match the phones ,
Do you get out a a vector of these ones and zeros and then try to find the closest matching phoneme to that vector ,
So you recognize a phone and which ever phone was recognized , you spit out it 's vector of ones and zeros .

voice , unvoice , and silence ,
Voice , unvoice , and si
usually for voiced - unvoiced you 'd do , you 'd do something you 'd do energy
one of the differences between voiced , unvoiced and silence is energy .
So if you just if you just had to pick two features to determine voiced - unvoiced , you 'd pick something about the spectrum like R - one over R - zero , and R - zero
if you were to sum up the probabilities for the voiced and for the unvoiced and for the silence here , we 've found in the past you 'll do better at voiced - unvoiced - silence than you do with this one .
So you 're saying take the features that go into the voiced - unvoiced - silence net and feed those into the other one , as additional inputs , rather than having a separate
Fif - fifty - six percent accurate for v voice - unvoice
I don't remember for voice - unvoice ,
If you 're getting fifty - six here , try adding together the probabilities of all of the voiced phones here and all of the unvoiced phones
, if the example I was giving was that if you had onset of voicing and end of voicing as being two kinds of events , then if you had those a all marked correctly , and you counted co - occurrences , you should get it completely right .
Let 's say , is this voicing , or is this not voicing ,

And so Morgan and I were discussing s s a form of a cheating experiment where we get we have a chosen set of features , or acoustic events ,
so i it would be a measure of " are we on the right track with the choices of our acoustic events " .
, , it 's it 's you get a distance measure at the end of the day ,

The the other thing I was suggesting , though , is that given that you 're talking about binary features , , maybe the first thing to do is just to count
and uses them to recreate the boundary for the test set .
So , this feature set called the sound patterns of English is just a bunch of binary valued features .
so whereas with our features , he 's actually storing the cepstrum on disk , and he reads those in .

And then the other thing that we were discussing was OK , how do you get the your training data .
similar amount of data to what you 're talking about with TIMIT training .
and if you have only a modest amount of data , you have trouble learning them .
So that for some subset of the training data , the the features I was computing were junk .
just it just seems like this behavior could be caused by s some of the training data being messed up .
On on the real data , not with artificial reverb ?
which I 'm guessing is the reason why the baseline was so bad .
I 'm g I 'm guessing it was the training data .
it 's a lot more training data .
So the question is how close to that one can you get if you transform the data using that system .
r Right , so I this SRI system is trained on a lot of s Broadcast News or Switchboard data .

What I trying two MLP to the with this new feature and the fifteen feature from the bus base system
And I put together the fifteen features and the three MLP output .
The inputs are the fifteen the fifteen bases feature .

And , , the result are li a little bit better , but more or less similar .
And then there 's these other meetings , like HLT and ASRU
And so I 'm gonna apply that to compare it with the results by King and Taylor who did these
That 's ac actually a little side point is that 's the first results that we have of any sort on the far field on the far field data for recorded in meetings .

So for my class project I 'm I 'm tinkering with support vector machines ?
so I 'm gonna do a similar thing with support vector machines
So what 's the advantage of support vector machines ?
. So , support vector machines are good with dealing with a less amount of data
So , the simple idea behind a support vector machine is , you have you have this feature space ,
s support vector goes back to that thing .

What are what are your f frame error rates for this ?
no , the frame error rate ?
but , what he 's talking about here is a a translation to a per - frame feature vector ,
I 'm using two second FFT analysis frames , stepped by a half second
so it 's a quarter length step
I take the current frame and the four past frames and the four future frames
I use that to normalize the s the current center frame by mean subtraction .

but I was gonna ask about the changes to the data in comparing PLP and mel cepstrum for the SRI system .
And I was asking if you were going to do redo it for PLP with the normalization done as it had been done for the mel cepstrum .
again the Cambridge folk found the PLP actually to be a little better .
And , so there 's no place where these where the cepstral files are stored , anywhere that go look at and compare to the PLP ones ,
that 's why c Cambridge switched to PLP .

And you just took this thing in here because it 's a neural net and neural nets are wonderful
because otherwise you 're asking the net to learn this
How long does it take , Carmen , to train up one of these nets ?
The targets for the neural net , , they come from forced alignments ?
using recurrent neural nets , they recognized a set of phonological features
, neural net approach or Gaussian mixtures for that matter are fairly brute force kinds of things , where you you predefine that there is this big bunch of parameters
So King and Taylor did this with recurrent neural nets ,
So they had one recurrent net for each particular feature ?

so there 's there 's actually plenty of meetings that are really relevant to computational speech processing of one sort or another .
my would be that this is since TIMIT 's read speech that this would be less of a big deal ,
if you went and looked at spontaneous speech it 'd be more of one .
Due to Avendano , I 'm taking s six seconds of speech ,
and that adds up to six seconds of speech .
And that was trained on clean speech only ,

and we train up a hybrid system to do phone recognition on TIMIT .
and you could do phone recognition then and wouldn't have any of the issues of the training of the net or
just to again , just to see if that information is sufficient to determine the phones .
I wo did they compare that , what if you just did phone recognition and did the reverse lookup .

And one of the arguments for making it later is let 's make that whatever techniques that we 're using work for something more than connected digits .
the Aurora setup of HDK training on clean TI - digits ,
in a phony reverberation case
, clean TI - digits is , like , pretty pristine training data ,
there 's some digits training in there .
, , one percent word error rate on digits is digit strings is not stellar ,
but given that this is real digits , as opposed to laboratory

Then I talked a little bit about continuing with these dynamic ev acoustic events ,
So i the idea is if we get good phone recognition results , using these set of acoustic events , then that says that these acoustic events are g sufficient to cover a set of phones ,
because it 's just Say , if you had ten events , that you were counting , each frame would only have a thousand possible values for these ten bits ,
and just count the co - occurrences and divide them by the occ count the co - occurrences between the event and the phone and divide them by the number of occurrences of the phone ,
and that would give you the likelihood of the of the event given the phone .
And the other thing would be , say , if you had these ten events , you 'd wanna see , what if you took two events or four events or ten events or t
You could define other events as being sequences of these events too .

No , satly the mes the Mel Cepstrum ,
but with the mel cepstral features .
Which talks about the com computation that his mel cepstrum thing does ,
When you get the mel When you go to the mel scale .
it 's bark scale ,
but produce mel cepstrum
which is what the typical mel cepstral filter bank does .
than for the mel cepstral , and that the average amount of pruning that was happening was therefore a little bit higher for the PLP features .

He did one PZM channel and one PDA channel .
it was about five percent error for the PZM channel .
it 's a much wider range of channels

the France Telecom proposal
Look insi look i carefully what they are doing with the program @ @ and
there 's some there 's like one over one plus the exponential like that .
or should it should it be coronal instead of not coronal as it was labelled in the paper ? "
The Mississippi State paper ?

, the issue is whether people make a decision now based on what they 've already seen , or they make it later .
So . I some of the progress , I 've been getting a getting my committee members for the quals .
I was looking I 've been studying and going through the logs for the system that Andreas created .
. I 've been , I 've been working with Jeremy on his project
it 's actually been awhile since I 've looked at it .

But that fifty - five was for the when the output are the fifty - six phone .
at the frame level for fifty - six that was the number we were getting for reduced band width .
, if you 're getting fifty - six percent over here ,
We don't have any set of parameters where we can say , " only process from a hundred and ten hertz to thirty - seven - fifty " .
And if you had if you had fifty filters , you 'd be throwing away hardly anything .
You can You can throw away below a hundred hertz or so

Right , but it seemed to me that what you were getting at before was that there is something about the difference between the original signal or the original FFT and with the filter which is what
And so the filter bank is chosen to integrate out the effects of pitch
The filter bank which is created by integrating over F T bins .
and it 's it it actually copies the the second filters over to the first .
If you had If you had ten filters , then you would be throwing away a lot at the two ends .
what you can do is you can definitely change the filter bank from being a trapezoidal integration to a a triangular one ,
but we did we did hear this comment from people at some point , that it they got some better results with the triangular filters rather than the trapezoidal .

And I 'm trying two MLP , one that only have t three output ,
and only have result with the MLP with the three output .
What what feeds the the three - output net ?
you could feed it a bunch of s you could feed two numbers that you wanted to multiply into a net
and train it to get the product of the output and it would work .
that that for the other one , for the three output , is sixty - two , sixty three more or less .

So I was going through and just double - checking that think first , to see if there was just some obvious bug in the way that I was computing the features .
and does all of the cepstral computation on the fly .
even though the cepstrum is already computed , he has to give it a front - end parameter file .
and then I 've been trying to track down this bug in the ICSI front - end features .
I was wondering if there 's maybe certain settings of the parameters when you compute PLP which would it to output mel cepstrum .
because I was I was thinking in terms of th this as being a a core item that once we once we had it going we would use for a number of the front - end things also .

and we 're we 're thinking about a way to test the completeness of a set of dynamic events .
, completeness in the in the sense that if we if we pick these X number of acoustic events , do they provide sufficient coverage for the phones that we 're trying to recognize or the f the words that we 're gonna try to recognize later on .
actually Adam ran the SRI recognizer .
, , if you 're doing a a sixteen digit credit card number you 'll get it wrong almost all the time .

But for dyed - in - the - wool speech people , that ICSLP and Eurospeech are much more targeted .
Cuz actually Mississippi State people did use support vector machines for speech recognition and they were using it to estimate probabilities .
s So Barry , if you just have zero and ones , how are you doing the speech recognition ?
I 'm not do I 'm not planning on doing speech recognition with it .
but people have used it for speech recognition , and they have gotten probabilities .

Because maybe they 're the threshold that they are using on the basis of this value
maybe everything is Maybe they tres hole are on basis of this .
So , since he used the same exact pruning thresholds for both , I was wondering if it could be that we 're getting more pruning .
He he He used the identical pruning thresholds even though the s the range of p of the likeli
but modify the pruning threshold and see if it , affects the score .
But you could if if that looks promising you could , , r run the overall test set with a with a few different pruning thresholds for both ,
and presumably he 's running at some pruning threshold that 's that 's , gets very few search errors

I don't I 'm not but I remember @ @ that I can't show that .
and , hhh I 'm trying to remember but I recall that Andreas was saying that he was gonna run the reverse experiment .
, I don't remember there being an independent way of saying " we 're just gonna make them from here to here " .

where used the simulated impulse response the error rate went from something like eighty it was from something like eighteen percent to four percent .
And on meeting rec recorder far mike digits , mike on channel F , it went from forty - one percent error to eight percent error .
. it was getting around one percent for the near for the n for the close mike .
and you have something like forty - one percent error
It 's something like five percent error with the distant mike ,
and one percent with the close mike .

, I 'm I 'm slightly confused .
No I was just trying to say if you b if you bring this into the picture over this , what more does it buy you ?
Wall Street Journal ,
There 's a cubic root that happens ,

, it goes back to nearest - neighbor thing ,
So a long time ago people talked about things where you would have a condensed nearest - neighbor ,
So rather than doing nearest neighbor where you compare to every single one , you just pick a few critical ones ,
but that in general it 's not that critical .
Right . , , generally in these things you turn back pruning really far ,

and you 'd be much lower error usually if you just multiplied it out .
And that 's what these dumb machine learning methods are good at .
I would think that you might wanna do something like , look at a few points to see where you are starting to get significant search errors .
and we see some reduction in error using some clever method ,
a significant reduction in the error for that would be great .

. I will look to try if I move this parameter in their code what happens ,
He 's that he is in Las Vegas like that .
So one thing that I did notice , yesterday I was studying the the RASTA code
, I went through the Feacalc code and then looked at just calling the RASTA libs and thing like that .
But it calls RASTA with some options ,
It 's trained on a lot of Switchboard , Call Home ,

So , it seems to me that the only reasonable starting point is to automatically translate the current TIMIT markings into the markings you want .
And it won't have the characteristic that you 'd like , of catching funny things that maybe aren't there from these automatic markings ,
and d did they use sigmoid or a softmax type thing ?
to see if maybe there was a a certain type of compression that was done that my script wasn't catching .
and if they trained the SRI system on this TV broadcast type ,
OK , so it 's then it 's it 's reasonable to expect it would be helpful if we used it with the SRI system

, at the front it says " log energy is equal to the rounded version of sixteen over the log of two "
So they 're taking the number inside the log and raising it to sixteen over log base two .
If we ignore the sixteen , the natural log of t one over the natural log of two times the natu
, it says , since you 're taking a natural log , it says that when you get down to essentially zero energy , this is gonna be the natural log of one , which is zero .
So it 'll go down to to {nonvocalsound} the natural log being
but , , as opposed to the log in the other case .
One of the things that I did notice was that the log likelihoods coming out of the log recognizer from the PLP data were much lower , much smaller ,
but , I I 'll leave my microphone on ?

but then you have something like spectral slope , which is you get like R - one ov over R - zero like that .
And so the thing that she was talking about before , was looking at something ab something about the difference between the log FFT log power and the log magnitude F - spectrum and the filter bank .
What about it you skip all the all the really clever things , and just fed the log magnitude spectrum into this ?
You have the log magnitude spectrum , and you were looking at that and the difference between the filter bank and c computing the variance .
And I calculate the spectral mean , of the log magnitude spectrum over that N .

what it i at the end of the day , what it actually does is it picks those examples of the features that are closest to the separating boundary ,
So , given these these features , or these examples , , critical examples , which they call support f support vectors , then given a new example , if the new example falls away from the boundary in one direction then it 's classified as being a part of this particular class
where you would you would pick out some representative examples which would be sufficient to represent to correctly classify everything that came in .
I it can be a reduced parameterization of the model by just keeping certain selected examples .

Given this regular old net that 's just for choosing for other purposes , add up the probabilities of the different subclasses and see how you do .
and count co - occurrences and get probabilities for a discrete HMM
and then that distance measure is is translated to a zero or one .
, they had a had a way to translate the distances into probabilities with the with the simple sigmoidal function .
So they have some conversion from these distances to probabilities .

Mc - McDonald 's constant .
that Stephane will arrive today or tomorrow .
But you 'd get all the other distinctions , , randomly wrong .
which implies that the networks are bushier ,

it probably just ignores it if it determines that it 's already in the right format
and it looks like we don't have any way to control the frequency range that we use in our analysis .
, ignore the lowest bins and the highest bins .
, so the idea is that the very lowest frequencies and typically the veriest highest frequencies are junk .
you just for continuity you just approximate them by the second to highest and second to lowest .

that I work I begin to work with a new feature to detect voice - unvoice .
and I asked John Ohala and he .
Cuz the Switchboard transcription project was half a dozen people , or so working off and on over a couple years ,
So what I was working on is just going through and checking the headers of the wavefiles ,
Looking the sampling rates to make all the sampling rates were what eight K , what I was assuming they were ,

, I will try to explain the thing that I did this week during this week .
Mmm , late in the summer sometime .
and also mmm I H Hynek last week say that if I have time to begin to study
And so far I have Morgan and Hynek , Mike Jordan ,
and a short amount of time ,
So I 'm I 'm reproducing phase one of their .
And the the run time of the recognizer on the PLP features is longer

the variance of the auto - correlation function , except the first point , because half the height value is R - zero
the first coefficient of the auto - correlation function .
Yes , yes , the variance of the auto - correlation function that uses that

and so you could make a table that would say , if you had thirty - nine phone categories , that would be a thousand by thirty - nine ,
Did you find any more mistakes in their tables ?
yesterday I brought Chuck the table
the I sh think they should be roughly equivalent ,
I for some particular database you might find that you could tune that and tweak that to get that a little better ,

