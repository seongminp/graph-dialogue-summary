But that 's really your choice , it 's your
, but , Again , I wouldn't wanna , wouldn't want what we produced to be so , know , local in perspective that it was matched , what we were thinking of doing one week ,

So , that 's that 's an indication ,
, so , . Anyway , just an indication once you get into this realm even if you 're looking at connected digits it can be pretty hard .
no , no it 's connected it 's connected , , digits ,
Even , I with vowels that would be pretty hard ,

, someone fills out the form and then they 're not at the meeting and so it 's blank .
, it 's it 's to have the same person do it just as a double - check , to make you 're entering for the right person .
When they 're wide awake , .
what I 'm I 'm a l little behind in what they 're doing , now , and , , the they 're doing on Switchboard now .
I might have done what you 're requesting , though I did it in the service of a different thing .
if it 's good , we don't then we 're we 're fine ,
We 're gonna be recording them every Monday ,
But they 're they 're generally very good .
they 're like it 's in the room .
but we 're , coming to some kinda closure , on that .
so we 're , a coup a week or two away I would say from ,
If it 's not then we 're really then we def definitely
Since they 're they 're like two hundred bucks a piece ,

And , so , You get , some of that information from Steve 's work on the on the labeling
So it would be it would be great if we had , either these , labelings on , the same portion of Switchboard that Steve marked , or , Steve 's type markings on this data , with these .
And Steve 's type is fairly it 's not that slow ,
And it 's more accurate than , phone labels .

And so , once we 're it 's done it would be very to train up a recognizer and actually start working with this data .
They 're running out of data unless we s make the decision that we should go over and start , , transcribing the other set .

so , , that that 's great , but what would be to have some more meetings , not just one meeting to be that , there is a system ,
, we have this meeting and the feature meeting and we have a couple others that we have , couple examples of . But but , ,
so , would you be training then , , the segmenter so that , it could , on the basis of that , segment the rest of the meeting ?
Do you have any of Jerry 's meetings in your , pack , er ,
and I could easily give them Jerry Feldman 's meeting ,
However , he may be solicited after these meetings are distributed .
So if we go to a workshop about all this it 's gonna be a meeting about meetings .
, , what Which 'll be the meeting about the meeting .
Cuz then it would be a meeting about the meeting about meetings .

So , it 's gonna be either a gloss or it 's gonna be a vocal sound like a , laugh or a cough , or , .
Or a non - vocal sound like a doors door - slam , and that can be easily done with a , , just a one little additional thing in the , in the general format .
And then there 's also , things like door - slams that 's really in no one 's channel ,

, the there 's one microphone that 's close , that they have as this thing , close versus distant .
I don't think Morgan 's suggesting that we do that , though .
Since , what I decided to do , on Morgan 's suggestion , was just get two , new microphones , , and try them out .

and maybe you 'd find that it worked in , in the , case of the pr of the , , non - predictable .
, , they , they 're interested in continuing working with us ,
And , , I tested it on three or four meetings and it seems to work , , fairly , I would say .
That 's that 's what I that 's my future work .
Of of the meetings that you 're working with , how many of them are different , tha
, they 're still working they still have enough to finish that I haven't assigned a new meeting ,

, so that the reason it 's not just a transcript is that there 're false starts , and misreads , and miscues and things like that .
And you do this gross thing saying " I it 's this phone starting there " .
So in our case you 'd think about us s starting with maybe the regular dictionary entry ,
Or you could start from the if we were gonna , do the same set , of sentences that Steve had , done , we could start with those transcriptions .
, no , if we were to start with this and then tweak it h manually , would that would be OK ?
s that 's probably our agenda , or starting up there .

and that 's just what I used to generate the order . of these particular ones .
, but , in order to do that we need to extract out the actual digits .
And so , , , it 's easy to create the files and leave them blank , and so actually we could do it in either order .
just by way of , a , order of magnitude , , , we 've been working with this Aurora , data set .
And it 's still like an order of magnitude worse than what humans do .
so that 's why the human transcriber 's giving you the that pronunciation ,

and it 's a it 's a fine idea partly because , , it 's not un unrelated to their present skill set ,
, , I I 'm jus at the moment we 're just talking about what , to provide as a tool for people to do research who have different ideas about how to do it .
, so if we could get a couple meetings done with that level of precision that would be a good idea .
but , if they 're in the wrong channel , that 's , not a good idea .
And , Jane had this , , idea of having , like an extra , couple tiers ,
So the idea is then , , Don can take , , Jane 's post - processed channelized version , and , with some scripts , , convert that to a reference for the recognizer

It 's , , it 's by Crown ,
For the recor for the record Adam is not a paid employee or a consultant of Crown .
I said " For the record Adam is not a paid consultant or employee of Crown " .

And , , , so , I mentioned the process that I 'm going through with the data ,
so that 's a good you can always clean that up , post - processing .
, if that process is automatic once we get your post - process , transcript .
and that 's where , we , might wanna have this individual , , ha have your pre - process input .

I have thirty minutes that I 've more tightly transcribed with reference to individual channels .
and then I took his tool , and last night for the first thirty minutes of one of these transcripts , I , tightened up the , , boundaries on individual speakers ' channels ,
, we could easily , get a section , , like say a minute or so , from every meeting that we have so f from the newer ones that we 're working on , everyone that we have .
If it 's not the first minute of the meeting , that 's OK with me ,
So . What what I 'd quite like , perhaps , is , to have , some five minutes of of different meetings ,
So , if I give you like five minutes is the idea that this would then be applied to , , to , providing tighter time bands ?
OK , so then , if that 's five minutes per meeting we 've got like twelve minutes , twelve meetings , roughly , that I 'm that I 've been working with , then

but it will add , for them , an extra dimension , it might be an interesting break for them .
because if you add them to the dictionary and you run recognition , you add confusion .
So people purposely don't add them .
You can add the features in , , but it 'll be underspecified .
, so , what where this is , , I want would like to have something that 's useful to people other than those who are doing the specific research I have in mind ,
so , that 's that 's great for my purpose .

OK , the , w as you can see from the numbers on the digits we 're almost done .
, and so , , we probably will be done with the TI - digits in , , another couple weeks . , depending on how many we read each time .
are they reading actual phone numbers ,
But in TI - digits , they 're reading things like zip codes and phone numbers and things like that ,
But , It could be that when we 're reading digits , because it 's it 's for such a limited set , that maybe that phenomenon doesn't occur as much .
it 's definitely true that , when people are , reading , even if they 're - reading what , they had said spontaneously , that they have very different patterns .
So the fact that they 're reading , first of all , whether they 're reading in a room of , people , or rea , just the fact that they 're reading will make a difference .

So I 'm it 's fine , that part .
and , they could be overlapping in all sorts of bizarre ways that don't correspond to the timing on phones .
, I was thinking that it would be interesting , to do it with respect to , parts of Switchboard anyway , in terms of ,
So , , e so the , , we have the , th they transcribe as if it 's one channel with these with the slashes to separate the overlapping parts .
and then that means that , if a person contributed more than once in a given , overlap during that time bend that two parts of the utterance end up together , it 's the same channel ,

That with these , the grouping , there 's no grouping , and so it 's just the only discontinuity you have is at the beginning and the end .
But it 's it 's the best compromise that a group of people scratching their heads could come up with to describe what happened .
and , then you have the difference between the networks group and this group
It 's comfortable and stays on the head ,

the problem is when you run , , if you run a regular dictionary , , even if you have variants , in there , which most people don't , you don't always get , out , the actual pronunciations ,
And then we run it through then it then I 'm gonna edit it and I 'm gonna run it through channelize which takes it into Dave Gelbart 's form format .
cuz we 're running the evals
So they get it into the multi - channel format and then adjust the timebands so it 's precise .
So they 're really running out of , data , prett that 's good .
And , then , I run it through , , the channelize program to get it into the multi - channel format , OK .

because , we you wanna know , both about the way that they 're producing a certain sound , and what kinds of , what kinds of , phonemic , differences you get between these , transcribed , sequences and the dictionary ones .
the other difference is that the features , are not synchronous ,
Even probably with the gains differently will affect it , you mean
but , I 'm there 's no difference between ,

It 's the beginning of time in speech recognition .
It 's like the , single cell , , it 's the beginning of life ,
So that 's sorta qualitatively different .
I hadn't , , incorporated , a convention explicitly to handle acronyms , ,
And to incorporate , , keyword , at the beginning .

but it wasn't artificially added to get some artificial signal - to - noise ratio .
But that it 's really it 's close - talking mikes , no noise , clean signal , just digits , , every everything is good .
It 's just having , multiple levels of , information and marking , on the signal .
So it 's not a strictly one - dimensional signal .
the good example was an inbreath , where a transcriber working from , the mixed , signal , doesn't know whose breath it is ,

So it 's useful to know which variant was produced , at least at the phone level .
Some low - level features , which are not , fully , , phone classification .
And the th this particular image , of how thi how it 's done , is that , then given all of these estimates at that level , there 's a level above it , then which is making , some sound unit classification such as , , phone
, and but it 's still open within that whether you would have an intermediate level in which it was actually phones , or not .
That , that if we , can we should put in , , another level of , of description there if we 're gonna get into some of this low - level .
partly to see , if you could , generate first guesses at what the articulatory feature would be , based on the phone representation at that lower level .
You 'd have it , from the lowest level , the ac acoustic features , then you 'd have the , , the phonetic level that Steve did ,
They 'd be able to do phonetic - level coding , or articulatory .

it 's also , there 's , really a difference between , the pronunciation models in the dictionary , and , the pronunciations that people produce .
One , one is going from a dictionary pronunciation of something , like , " gonna see you tomorrow " ,
Gonna see you tomorrow , , " guh see you tomorrow " .
Because , it 's not , , that easy to go from the , dictionary , word pronuncia the dictionary phone pronunciation , to the gestural one without this intermediate or a syllable level , representation .
it 's also useful to have some level of representation which is , is a reduced it 's a pronunciation variant , that currently the dictionaries don't give you
But . And it 's more accurate than the than the dictionary or , if you 've got a pronunciation lexicon that has three or four ,
So that 's probably the right way to go anyway , is to is to start off with an automatic system with a pretty rich pronunciation dictionary that , , , tries , to label it all .
, regular dictionary , , this is a pretty rich dictionary .

And then , hand off to Jane , and the transcribers to do the actual extraction of the digits .
But , once that 's moved over , , hopefully in a couple days , then , we can take , , what Jane just told us about as , the presegmented , {nonvocalsound} the segmentations that you did , at level eight or som at some , threshold that Jane , tha right , and try doing , forced alignment . , on the word strings .
but , I would have maybe a transciber , , look at the result of a forced alignment and then adjust those .
And then there 's this interesting issue Jane brought up
it 's probably good enough for force - alignment .

there 's these overlapping processes where some voicing some up and then some , , some nasality is comes in here , and .
so you would say , , it 's voiced through here , and so you have label here , and you have nas nasal here ,
And then there are other cases where , nasality , voicing

, that 's about articulatory features , about , points of articulation , which means , , rather than vowels .
And you can go from not from that to the articulatory features , but that would be a better starting point for marking , the gestural features , then , data where you don't have that ,
an and in some places it would fill in , So the kinds of gestural features are not everywhere .

And I that includes some the filtering for the , the ASI refs , too .
And , that , , I 'm not , that one I 'm not so if it 's into the , things that , I , wanted to use the hours for ,
OK , then , , if I were to include all together samples from twelve meetings that would only take an hour
, what is , that would be an hour sampled , and then they 'd transcribe those that hour ,
, last night , I did about half an hour in , three hours , which is not , terrific ,
anyway , it 's an hour and a half per

The the question is , do they do that on , meeting data ?
maybe meeting data isn't the right corpus .
And then , , As we get , further down the road and we can do more things ahead of time , we can , do some of the same things to the meeting data .
so , , I get the data back from the transcri , s , metaphorically , get the data back from the transcriber ,

, so I wanted to discuss digits briefly , but that won't take too long .
So , , , Liz , and Don , and I met this morning , in the BARCO room , with the lecture hall ,
And the , what we discussed this morning , I would summarize as saying that , , these units that result , in a particular channel and a particular timeband , at that level , , vary in length .
So , that 's that 's what we were discussing , this morning as far as I Among

I 've been do I 've done , eight meetings , something like that , just by hand .
And we 've only recently got it to anywhere near human .
The reason for doing it is because the argument is that certainly with conversational speech , the that we 've looked at here before , , just doing the simple mapping , from , , the phone , to the corresponding features that you could look up in a book , , isn't right .
because I 've seen , where does the voicing bar start and .
, we 've probably have a separate , , discussion of , of whether you can do that .
, just from what I 've seen , , there are some where , , you 're present or not present ,
y it 's and so , , I 've I 've incorporated also convention , with that
and they 've been assigning it to someone that may or may not be correct .
I 've been I 've been adding that to the ones I 've been editing .

Mitch showed that , and some , dissertations have shown that .
That 's , isn't that that was , but that wasn't that kinda the direction ?
He 's got lip lipsmacks .
Don't worry about finishing your dissertation .

So the The point there , and this is car noise , things , but real situation ,
instead of instead of having a projector noise it 's it 's car noise .
It was just people driving around in a car .

as there are some problems in , when , in the channel , there they the speaker doesn't doesn't talk much or doesn't talk .
OK , now you 're saying different meetings because of different speakers or because of different audio quality or both or ?
Different different number of speakers , different conditions .
wa in terms of the speakers or the conditions or the ?
and having as much variety for speaker certainly would be a big part of that .
So if they hear a breath and they who breath it is it 's better to put it in that channel than to put it in the speaker 's channel
e w would that be a single speaker or is that multiple speakers overlapping ?
like if there 's one speaker in there , that says " OK " , right in the middle , it 's gonna have a lot of dead time around it ,

It 'll it 'll be it 'll be a re - cap of a meeting that we had jointly this morning .
, so it 'll put on the screen , " The next set is six nine , nine two " .
OK , so , , what I 'll do then is I 'll go ahead and enter , this data .
So i we 'll see wha how much we can , , get the people to do , and how much money we 'll have and all this thing ,
, that 'll be , very useful to getting the overlaps to be more precise all the way through .
and I 'll mention it to , transcribers for the next phase
, but for free recognition I 'm it 'll probably not be good enough .

One particular test set of TI - digits .
So , I extracted , Ther - there was a file sitting around which people have used here as a test set .
So , I 'm impressed by what we could do , Is take the standard training set for TI - digits , train up with whatever , , great features we think we have , , and then test on this test set .
And so I have a set of scripts and X Waves where you just select the portion , hit R ,
And , , the best score , on the , nicest part of the data , that is , where you 've got training and test set that are the same kinds of noise and , , is about ,
Also you were thinking of a much more restricted set of features , that
It 'd be a complete , set then .
And I 'm and these people might they are , s most of them are trained with IPA .
, that 's the one wh where I do the training on so I can't do the evaluation on
what are we talking about in terms of the number of minutes you 'd like to have as your as your training set ?

There are some problems with the lapel mike .
but , there are some as I said some problems with the lapel mike ,
So it 's just the lapel versus everything else ?
so the only thing we 'll have extra now is just the lapel .

And so it 's just , , typing in name , times time , date , and so on .
cuz his interface allows me to have total flexibility in the time tags across the channels .
time so the meetings vary in length ,
cuz I would save a lot of , , time , dividing things .

Actually maybe they 're using phone recognizers .
but we don't have a really good , meeting , recorder or recognizer or transcriber or anything yet ,
we haven't done this yet because , , , Andreas an is gonna move over the SRI recognizer .
i I ran out of machines at SRI ,
it drifted into the afternoon , , concerning this issue of , , the , there 's the issue of the interplay between the transcript format and the processing that , they need to do for , the SRI recognizer .
we j we just needed a way to , strip , , all the comments , all the things th the that linguist wants but the recognizer can't do anything with .
So when that 's , ready , as soon as that 's ready , and as soon as the recognizer is here we can get , twelve hours of force - aligned and recognized data .

because the , the time that they 'd be spending doing that they wouldn't be able to be putting more words on .
So , you might have someone who just has a wor has words with states , and has , comes from articulatory gestures to that .
it might be neat to do some , phonetic , features on these , nonword words .
Are are these kinds of words that people never the " "s and the " "s and the " " and the
but , I yet whether these , segments that contain a lot of pauses around the words , will work or not .
Right . It 's not the it 's not the fact that we can't process a twenty second segment , it 's the fact that , there 's twenty seconds in which to place one word in the wrong place

i you should . It should be such that if you , , if you had o , all of the features , determined that you that you were ch have chosen , that would tell you , , in the steady - state case , , the phone .
And the inter - annotator agreement was not that good ,
, if you 're gonna add the features
Might not be , , exact features that , Jakobson thought of .
, , if we 're talking about , having the , annotators annotate these kinds of features , it seems like ,
But it might be good to do what Jane was saying , , seed it , with , guesses about what we think the features are , based on , , the phone or Steve 's transcriptions . to make it quicker .
And to , , to , , to normalize also loudness and modified loudness and things and that those special features actually are in my feature vector .

and then , presumably , we should go to the distant mike , and it should do poorly .
Are the , , wireless , different than the wired , mikes , ?
I 'm I 'm not , , if there are any wired mikes in those meetings , or , , I have to loo have a look at them
So it 's a replacement for this headset mike ?
What 's the , , style of the headset ?
And I checked on the web , and every site I went to , raved about this particular mike .

Hafta think about , the particular acoustic features to mark , too , because , , some things , they wouldn't be able to mark , like , , , , tense lax .
And , that it would be to have these , intermediate , or these some these reduced pronunciations that those transcribers had marked or to have people mark those as .
Th - there 'll be no way for you to actually mark what was said completely by features .

but that we got this is the typical number , for all of the , , things in this task , all of the , , languages .
It 's got , got a fair number of pronunciations in it
And then , a similar conv , convention for numbers .

It 's gonna be fun to see how we , compare at this .
not with our current system but you could imagine designing a system , that the states were features , rather than phones .
But that , Steve and the gang are doing , something with an automatic system first and then doing some adjustment .
And , I , then the evaluation of the system is a little bit hard , as I don't have any references .
I would quite like to have some manually transcribed references for the system , as I 'm not if it 's really good to compare with some other automatic , found boundaries .
or Pi - Tcl TCL .

And you find that , and , hit the key and it records it in a file in a particular format .
There 's one other small bit , which is just entering the information which at s which is at the top of this form , onto the computer , to go along with the where the digits are recorded automatically .
So it 's it 's just I have a file whi which has this information on it , and then when you start using my scripts , for extracting the times , it adds the times at the bottom of the file .
s @ @ . It s strikes me that there are more each of them is more informative because it 's so , random ,
So , may maybe the thing will be do to take some very small subset , not have a big , program , but take a small set , , subset of the conversational speech and a small subset of the digits ,
and then I , check for simple things like spelling errors and things like that .

So we 'll have a corpus that 's the size of TI - digits ?
So if you were doing ten digit , , recognition , you would really be in trouble .
the prosodics are not the same as TI - digits , .
One thought might be to do this , on the digits , or some piece of the digits .
So , I 'm I 'm glad that there is the digit part , where everybody is forced to say something ,
And if they do need to be further broken down then maybe it just be piece - wise , maybe it won't be the whole thing .

and , . You could argue what , what a sound unit should be , and .
And , , {nonvocalsound} their recognizer would prefer that the units not be overly long .
But it 's really an empirical question , whether the units we get at this point through , just that process I described might be sufficient for them .
And then we 'll see if the units that we 're getting , , with the at that level , are sufficient .
I 'm just hoping that the units that are provided in that way , {nonvocalsound} will be sufficient

H That could be an interesting design , too , cuz then you 'd have the com the comparison of the , , predictable speech versus the less predictable speech
, , , I worked a little bit on the on the presegmentation to get another version which does channel - specific , , speech - nonspeech detection .
And , and , therefore to be able to , , somewhat distinguish between foreground and background speech in the different in each channel .
So , can the transcribers perhaps do some , some meetings in terms of speech - nonspeech in the specific channels ?
Do the transcribers actually start wi with , , transcribing new meetings , or are they ?
I that perhaps the transcribers could start then from the those mult multi - channel , , speech - nonspeech detections , if they would like to .

And , what I did is I used some normalized features which , , look in into the which is normalized energy , , energy normalized by the mean over the channels and by the , minimum over the , other .
So I understand that 's what you were saying about your problem with , minimum .
So new use ninetieth quartile , rather than , minimum .
Then , the , , there are there are some problems with with n with normalization , and , then , , there the system doesn't work .
and , , when I s when I mentioned that we thought it was uncomfortable he said it was a common problem with the Sony .

And so I was in the process of like editing them but this is wonderful news .
And , , I 'm going to be doing a more thorough editing , with respect to consistency of the conventions .
So , as a first pass through , a first chance without having to do a lot of hand - editing , what we 're gonna do , is , I 'll run it through channelize , give them those data after I 've done the editing process and be it 's clean .
And do that , pretty quickly , with just , that minimal editing , without having to hand - break things .
but that 's easy to handle at the post editing phase ,
, and also I 'll be , , encoding , as I do my post - editing , the , things that are in curly brackets , which are clarificational material .
And that doesn't the amount of editing that it would require is not very much either .

No they don't have this you have to enter the data before , you do the second task , but they don't have to happen at the same time .
So I 'm I 'm not how much of effect that will have .
The only thing is I 'm a little concerned that maybe the phenomena , in w i
And you get the relative gain up ahead .

For the references that we need to go from the fancy transcripts to the {nonvocalsound} brain - dead .
And also it is contributing to the , , c composition of the transcript
cuz we can incorporate those numbers directly and it 'll be a more complete transcript .
That maybe , although the meeting context is great , that he has transcriptions that give you the actual phone sequence .
All I 'm saying is that , it is useful to have that the transcription of what was really said , and which syllables were reduced .
cuz the , and then also , if you did it on Switchboard , you would have , the full continuum of transcriptions .
Alright , so based on the phone transcripts they would all be synchronous , but then you could imagine , nudging them here and there .
So this , blends nicely into the update on transcripts .
but if someone says , PZM it would be to have that be directly interpretable from , the transcript what they said ,
but I was , realizing as I went through the transcripts , that there are some noises like ,

, the models are pretty crappy ?
One question I have that , we wouldn't know the answer to now but might , do some guessing , but I was talking before about doing some model modeling of arti , marking of articulatory , features , with overlap and so on .
you 'd you 'd want models for spreading .
, but to keep things that we mapped to like reject models , or , , , mouth noise , or , cough .
And what we do is , if it 's a breath sound , , a sound from the speaker , we map it , to , a noise model , like a mouth - noise model in the recognizer ,

So there 's also the not just the prosody but the cross the cross - word modeling is probably quite different .
but , perhaps we can do something with cross - correlations to , to get rid of the of those .
what I want to do is to look into cross - correlations for removing those , false overlaps .
We 'll probably get lots of errors because of the cross - talk , and , noises and things .

the best score was something like five percent , , error , per digit .
One and a half percent , two percent , something like that ?
but it was but it 's but . The very best system that I saw in the literature was a point two five percent that somebody had at Bell Labs , or . , but . But , , pulling out all the stops .
But a lot of systems get half a percent , or three - quarters a percent ,

, but I I was , like he said , I was gonna bring John in and ask John what he thought .
but the particular reason why I was interested in doing that was because I remember , when that happened , and , John Ohala was over here and he was looking at the spectrograms of the more difficult ones .
So there are some things that you don't have access to either from your ear or the spectrogram ,
But , The but where I 'm coming from is , , we 're coming off of that Larry Saul did with , , , John Dalan and Muzim Rahim in which , , they , , have , , a m a multi - band system that is , , trained through a combination of gradient learning an and EM , to , estimate , , the , , value for m for a particular feature .
And this is part of a larger , image that John Dalan has about how the human brain does it in which he 's imagining that , individual frequency channels are coming up with their own estimate , of these , these kinds of something like this .
it is telephone band , so , the bandwidth might be
so I , and this would be up their alley , so , we could when the when you d meet with , with John Ohala and find , what taxonomy you want to apply , then , they 'd be , good to train onto it .
and it 's one of these mount around the ear thingies ,

that was with , many sites competing , and this was the very best score and ,
But What I 'm imagining is a score - like notation , where each line is a particular feature .
I remember when at one of the Switchboard , workshops , that when we talked about doing the transcription project , Dave Talkin said , " can't be done " .
But not just fill pauses but all kinds of ways of interrupting and .
And then it we have to go to the planning session for that workshop .
Pause between the lines , remember ?

and you that might end up with more a closer correspondence .
So , is it , , bilabial or dental or is it , , palatal .
the on the only thing is that , What you actually will end en end up with is something ,
so , the string that you end up with isn't , actually , what happened .

