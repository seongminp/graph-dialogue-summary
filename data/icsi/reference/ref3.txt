a test run of the data collection design was very successful the group decided to hire the wizard and continue with the refinement of the design and recruitment of subjects on the other hand there was a presentation of a new version of the beliefnet for the vistaentertango mode task it is not a working net yet but identifying clusters of features that define the output mode provides a visual aid for further work there are potential problems from a combinatorics perspective these can be tackled either with technical adjustments or through careful knowledge engineering a base solution for the task would be to simply add some extra actionmode rules in the smartkom system action modes however can be inferred more efficiently by feeding a collection of features from the ontology discourse history parsing etc into bayesnets that would replace those rules ideally the results of this small task will give insights into the function of linguistic deep understanding for instance the final combination of features used in the current study may form a representation of the ontology general enough to employ in any task that includes trajectors and paths although the data collection test went well and it was decided to hire the wizard there are minor amendments in the procedure to be carried out shortenting the preparatory reading numbering tasks etc  a presentation of the data collection design should be included in the forthcoming meeting with other research groups along with some account of the system design and the use of beliefnets the structure of the latter was a major issue during the meeting their input vector is to be provided by information extracted from the various modules of the system such as the ontology and discourse history using standard rulebased methods the output action essentially provides additional semantic parameters for the xschema and in turn may trigger the collection of more features from the data the feature extraction could be carried out by a software tool checking object feature trees and filling them with appropriate values for this concept to be put to work further refinement of the beliefnet variables is necessary with particular attention on the combinatorics involved after the trial run of the experiment some minor issues like the length of the preliminary reading and the need to order the tasks given to the subjects were highlighted it is also possible that the pool of subjects ends up comprising almost entirely of students more variation in the sample is needed from a system design perspective the progress so far has shown that the combinatorics of the bayesnet even for a simple task like the choice of vistaentertango mode could render it unmanageable the beliefnet presented in the meeting is not a working bayesnet consequently it is as yet unclear what the decision nodes in the net are and what values these can take even if those were decided how to extract the necessary information from the data would still be an open issue looking at the bigger picture the current task is yet to provide insights into more general ways to achieve linguistic deep understanding with these intricacies in mind it is not easy to put together a presentation of the project cohesive and attractive enough for the other research groups in the institute the first trial run of the experiments was very successful after reading some information on a city the subject acting as a tourist has to ask for information over a phoneline in order to carry out certain tasks a wizard on the other side of the line pretends to be a computer system for half of the duration for the second half the subject is aware of communicating with another human in parallel to the data collection there was further work on the beliefnet for the inferences currently studied the features determining the output mode vista enter or tango of the beliefnet have been grouped in categories trajector landmark source path goal parse prosody world knowledge discourse and context every particular feature like time of day being in a hurry business or tourism etc will fit into on these categories although the presented net is not a working bayesnet yet it serves as a visual aid and stepping stone for the work to follow 
the work carried out on the recognisertoparser interface and the generator module will complete the translation of the current system into english from there on the system can be extended for the tourist domain and include a richer representation of the user intentions the current experiments involving subjects asking for tourist information through a computer call system are expected to provide relevant linguistic data this extension will require an enhancement of the current design the dialogue knowledge modeler and action planner modules need to interact and update each others state on the other hand they have to be separate since the dialogue manager is seen as part of a set of kernel modules to which different function modules can attach the inputs to the action planner are actually the output decisions of a beliefnet which will combine information derived from the user and situation models the ontology and the parser the new release of the latter will include syntactic and morphological information and utterance segmentation also deduced from the parse and fed into the beliefnet will be semantic constructions such as the sourcepathgoal image schema as the generator module is being translated to english it was agreed that the best approach is to use the same grammar as in german as this also produces syntactic trees the same approach is going to be taken for the new parser release a single system is going to be used for german and english with possible code extensions to be written to accommodate the differences the new parser needs to be fast and robust in dealing with speech input the verbmobil and forwiss chunk parsers can provide with a valuable paradigm it was also agreed that the enhanced knowledge model that is going to be produced with the use of the beliefnets will need to integrate with parallel developments in the design of dialogues some of the terminology will also have to be adapted another meeting was scheduled to take place before the departure of the german visitors in order to discuss future objectives of smartkom a native english speaker will have to oversee the generator translation and resolve any grammar issues that may arise a few issues regarding the ongoing development of the project came into focus the current m3l specifications are incomplete as to tourist path information and intention recognition the current parser itself extracts no syntactic information a more sophisticated parser is needed yet most of the available ones would not satisfy the speed requirements of the project the beliefnet whose inputs include the parse is not fully instantiated yet some rules of combination and conditional probabilities are not there yet also underspecified are the details of the interaction between different modules the dialogue manager and action planner although separate modules need to interact closely and update each others state the current dialogue manager is also designed with a much narrower domain in mind finally some ambiguities and other terminology issues were identified although it is not clear how difficult changes may be the translation of the tv and cinema listings system to english is almost complete the code of the recognisertoparser interface has already been written and variations on the lattices are currently being tested as for the enhanced knowledge modeler there is already a beliefnet most of whose features from the user and the situation model that influence the users intentions have been identified further linguistic factors can be found in the utterance some of them will emerge from the data collection which is underway one of the possible outputs of the knowledge modeler will be towards the dialogue manager viewed as a state transition network xml schemas coding these networks are currently being created 
the meeting was taken up by discussion about a thesis proposal and a talk about to take place at eml the latter will present the work that is currently being done at icsi including examples of inference of user intentions and of the recordings of the ongoing data collection the talk will also outline the theoretical xschemas image schemas bayesnets and neural background the thesis proposal on the other hand presents the idea of construal and makes claims as to how inferences are drawn in a probabilistic relational model by using information from the ontology situation user and discourse models it was advised that more emphasis should be put on the role of construal in the understanding of metaphor and metonymy base constructions deal with the norm while further general domain mechanisms determine how the constructions are invoked depending on the context several potential examples of polysemy were discussed in detail walkrun into on the bus out of film where is x however none of them was an example of lexical polysemy resolved by construal straightforward enough to include in the proposal the tourist domain is not metaphor rich as the talk at eml will also refer to a theoretical framework it was suggested that along with presenting ntl and the piece on mirror neurons it also alludes to relevant fmri work the neural side of the research could be of interest to various groups the language analysis itself will be introduced in terms of image schemas on the other hand it was arranged for more feedback on the thesis proposal to be sent by email the latest version of the construction formalism will also be needed to complete the presentation it was noted that the thesis proposal did not put any emphasis on metaphor or on the scalability achieved by combining constructions with general construal mechanisms constructions cover base cases while metaphoric and metonymic cases are resolved with the extra help provided by construal during this discussion however the suggested examples of polysemy which is tackled by the proposed framework were not straightforward enough it was agreed that metaphors are not abundant in the spatial domain some of the candidates discussed were phrases like on the bus out of film nonspatial uses of where or other fixed expressions the thesis proposal focuses on how construal works in the tourist domain one can build a probabilistic relational model with domain general rules that define how ontology situation user and discourse models combine to infer intentions the talk for eml includes a presentation of the motivation behind the project as well as the work already done on smartkom parser generator synthesis  furthermore the data collection currently taking place and some preliminary observations are going to be outlined all this is going to be given from the perspective of the general theoretical framework ntl with further explanations on xschemas and also the embodied simulation approach 
the current corpus of data comprises twelve hours of recordings of which fortyfive minutes are transcribed up to fifty hours of controlled recordings are expected to be completed in the next six months additional material acquired through collaborations with local broadcast media and uw will probably bring the total to more than a hundrend hours a revised consent form to be signed by the participants is being put together the first transcribed session is being used for the marking and labeling of speaker overlaps this manual coding of the overlapping zones can be compared with automatic detections of such zones a simple program to achieve those by checking and filtering energy increases is also being developed the potential usefulness of block echo cancellation was put forward its study would test the initial consensus which favoured feature approaches for the recogniser instead the digitreading parts of the meetings would be appropriate data for this study there was also mention of the potential future gain in the analysis of meetings from the study of the inference of implicit knowledge structures a preliminary look at the data suggested that these are abundant in the recorded sessions in order to increase the number and variety of the recorded data the group will contact the local broadcast media and discuss the possibility of arranging specially set up recordings of discussion panels further contacts can also be made within icsi or the university in general the digitreading will not have to be done in all these recordings what is necessary though is that all recordings are made using both close and distant mikes the revised consent forms will be valid for ten meetings it was agreed that although its good practice to avoid sensitive material in the recordings complete anonymisation would make them unnatural from a research point of view only exploratory work preliminary measurements etc can be done until more data are collected the transcription of the acoustic events in the first session will continue but focusing only on speaker overlaps in order to speed up progress parallelly a simple program to detect those overlapping zones will be run and its results compared with the handcoded material finally it was agreed that there will be further study into the use of inference structures in the analysis of meetings more closely it will be difficult to recruit many groups that would agree to have their meetings recorded regularly however the use of found data is not possible as they are not recorded in the required setup the point of potential legal problems with the presence of sensitive material in the recordings or the identification of individuals was also raised the latter gave rise to difficulties that pronoun identification may pose in future analysis there was some delay in sending the first batch of recordings for transcription due to some missing files it is also hard to speculate how long it will take ibm to carry out these transcriptions furthermore even when they are completed and sent back they will need another passthrough for adjustment to the requirements of the project also timeconsuming would be the detailed transcription of all acoustic events as it took twelve hours to analyze twelve recorded minutes as to these acoustic events there is significant variation in their respective numbers depending on whether the data used come from the close or the distant microphones moreover the issue of block echo cancellation was reopened although its use may be problematic for this specific data a fortyfive minute session has already been transcribed at icsi and also sent to ibm another twelve hours have been recorded and are currently being put on cds in order to be sent to ibm for transcription there are already arrangements in place for the regular recording of some morning meetings as well as those by the natural language and network services teams problems with crashing equipment are being sorted out jose has completed a detailed marking and labeling of all one thousand acoustic events in the first twelve minutes of the transcribed session mentioned above he has counted three hundrend overlapping zones in the whole session in the meantime adam is working on a revised interface for the transcription of these zones a simple program to locate overlapping zones automatically by in a nutshell detecting energy increases in the signal is being written its output can be impported into transcriber other potentially useful scripts that are ready include one for a crosscorrelation filter which cleans up the original signal and some for automatic transcription of digits finally a preliminary check on the usefulness of inference structures in the analysis of meetings was carried out 
the main topics discussed were the results of digit recognition and the forced alignment task realisations as to the former included the surprisingly good results from the lapel microphones and the fact that the widelyused htkbased systems performed worse than sri which however is specifically trained on digits for the results to be more closely comparable it was suggested that the ti digit corpus is used on the same system although the two corpora differ in recording conditions and amount of data per speaker other methods to improve recognition results are comparing the signals of close and farfield microphones or using the switchboard model for channel adaptation before speaker adaptation is carried out on the other hand there have been improvements on forced alignments although some issues still need debugging handmarked wordlevel alignment data would be very useful for the finetuning of more parameters finally a paper on overlap identification is being prepared for eurospeech this work can potentially be used for the planned research on prosodic features another two papers on segmentation and on the aurora system are also being submitted by icsi staff in order for the digit recognition results to be more reliably comparable it was suggested that the ti digit corpus is tested on sri as well additionally results are going to be checked by examining the signal from different microphones some modifications to the ti corpus may be needed to further consolidate this juxtaposition the ultimate purpose is to create a system that can be fed different features and will substitute htk as regards the forced alignments wordlevel alignments that have already been checked in waves could be merged with transcripts and utterancelevel representations produced in transcriber as both packages can use the ctm format more measurements and correspondence with data from other corpora callhome switchboard are going to be carried out with respect to backchanneling and overlaps the intention is to write a paper with the results of this task towards the end of the meeting the group discussed possible agenda topics for big meeting scheduled for the following saturday at the digit recognition task htk systems which are commonly used performed worse than sri the error rate with the current digit corpus is expected to be higher than with the ti one since the latter are wideband studio recordings the distance of the microphones from the speaker also affects the results the microphones themselves are not of the best quality although this has been a design choice furthermore it was noted that sri is somewhat cumbersome feeding features into the recogniser requires separate files to be dumped out for every segment to be processed there were also a couple of problematic points with forced alignments the pruning proved too severe and word locations needed to be constrained further using adaptation for both the foreground and the background speaker also resulted in some strange alignments moreover there were some speaker identification mistakes that occurred whilst transcribing from the mixed channel for the digit recognition task results from different microphones were taken the lapel mikes did well in this task since they capture less breath noises and there is less clothes rustling during the digit reading some obvious mistakes in the reading were deleted manually adaptation means and variance improved recognition results by 06 similarly work on forced alignments also gave better results at least with the data from native speakers it was enforced in the analysis that foreground speech be continuous moreover noise and background speech models were made meanwhile two transcripts have been manually aligned at utterance level this process has also shown that speaker identification works better when multiple channels are used a further conclusion was that backchanneling seemed to come mainly from the speaker that is more directly involved with the foreground utterance a paper on segmentation is being submitted to eurospeech and work on another one is being finished with the same intention the aim of the latter is to identify spurts and overlapped speech and tag them uniformly throughout the individual channels 
group members reported on their work progress the new features for the voicedunvoiced recognition experiment only improved results marginally the energy was included in the inputs but not the spectral slope which is also a voicedness factor alternative combinations of inputs will be implemented a second ongoing task concerns the ascertainment of the complete set of dynamic acoustic events sufficient for phone or word recognition at least in the timit corpus a test comparing recurrent neural nets with support vector machines for detection of phonological features in mfccs is also going to be run as part of a class project svms work like a condensed nearest neighbour and are reputed to learn patterns with less training data another comparison project in progress is the one between plp amd mel cepstrum for sri it is also proceeding with various checks being considered it is generally accepted that plp is more noise robust a final report summarised how the mean subtraction method shrank the error rates for the digit recognition this achievement suggests that the method should also be tried on better systems like sri for possible improvements in the voicedness detection it was suggested that the mlp inputs become simpler the net can be fed just with the log magnitude perhaps along with the variance over multiple frames the accuracy of the two nets should be compared by adding all the probabilities of voicedunvoiced phones in the 56output mlp the respective result in the other mlp should be at least as good at the same time the france telecom proposal and code will be studied closely for useful ideas regarding the acoustic events experiment it was recommended that a simpler task be done first eventphone cooccurrences should be counted in order to get phone probabilities for a discrete hmm the results can be used as base for the evaluation of more sophisticated methods an appropriately modified version of timit can be used as training data as for the plpmel cepstrum comparison a test is going to be carried out to check whether the pruning threshold is causing the search errors finally the subtraction method for spectral means will also be tested on sri since the base results for this were much better that for aurora the voicedness recognition results are only marginally better after the last experiment using a net with three outputs it shows that the issue is actually what the inputs to the net are the 63 accuracy for the voicedunvoiced net is not very good later as the france telecom proposal was discussed it was noted that a constant used in the energy expression looks equivocal with regard to the dynamic acoustic events experiments the markings offered by both the switchboard and timit corpus are not readily appropriate an automatic translation process will only provide some of the desired characteristics in the plpmel cepstrum comparison for sri a difference of a few percent has been found this could be due to differences in normalisation or a bug in the scripts it was also found that the amount of pruning was higher for the plp features and the run time of the recogniser longer finally as to the digit recognition the initial 41 error rate for the far mike was due to the training data being clean however for a real system even an error rate of 45 is very poor two mlps were trained on noisy timit for voicedunvoiced one with 3 outputs and one with 56 the former used three extra inputs spectrum difference variance autocorrelation function variance and r0 added to the 15 of the aurora base system its accuracy is 63 including noise while for the latter is 56 the nets only take about a day to train the planning of another neural net to define the complete set of acoustic events for phone recognition is also under way as to the plpmel cepstrum comparison for sri the headers of the wave files are being checked for compression inconsistencies or other data that may indicate a bug in the scripts responsible for the errors found furthermore while discussing the rasta code it was clarified that although there is no control on the frequency range in the fft this is done by the filter bank which ignores the highest and lowest bins as to digit recognition the mean subtraction method tested with the aurora setup resulted in reduction of error rates from 18 to 4 in ti digits and from 41 to 8 for meeting recorder farmike digits 
