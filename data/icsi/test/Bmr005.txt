E	doesn't look like it crashed .
E	that 's great .
G	so maybe what 's causing it to crash is keep starting it and then stopping it to see if it 's working .
G	and so starting it and then stopping it and starting it again causes it to crash .
G	so , won't do that anymore .
B	and it looks like you 've found way of mapping the location to the without having people have to give their names each time ?
A	sounds like an initialization thing .
B	it 's like you have the
B	are you going to write down that sat here ?
G	'm gonna collect the digit forms and write it down .
G	so they should be right
G	with what 's on the digit forms .
G	so 'll go ahead and start with digits .
G	and should say that , you just pau you just read each line an and then pause briefly .
E	and start by giving the transcript number .
D	transcript . , .
E	so , you see , don , the unbridled excitement of the work that we have on this project .
E	, it doesn't seem like bad idea to have that information .
G	and 'm surprised 'm surprised forgot that ,
E	'd it 's some
G	but that would be good thing to add .
G	after printed out zillion of them .
E	so do have an agenda suggestion .
E	we the things that we talk about in this meeting tend to be mixture of procedural mundane things and research points
E	and was thinking it was meeting couple of weeks ago that we spent much of the time talking about the mundane cuz that 's easier to get out of the way
E	and then we drifted into the research and maybe five minutes into that andreas had to leave .
E	so 'm suggesting we turn it around
E	and we have anybody has some mundane points that we could send an email later , hold them for bit , and let 's talk about the research - things .
E	so the one th one thing know that we have on that is we had talked couple weeks before about the the you were doing with attempting to locate events ,
E	we had little go around trying to figure out what you meant by " events "
E	but , , what we had meant by " events " was points of overlap between speakers .
E	but th gather from our discussion little earlier today that you also mean interruptions with something else
E	like some other noise .
E	you mean that as an event also .
E	so at any rate you were you 've done some work on that
E	and then the other thing would be it might be to have preliminary discussion of some of the other research areas that we 're thinking about doing .
E	especially since you haven't been in these meetings for little bit ,
E	maybe you have some discussion of some of the the plausible things to look at now that we 're starting to get data ,
E	and one of the things know that also came up is some discussions that that jane had with lokendra
E	about some some work about
E	don't want to try to say cuz 'll say it wrong ,
E	but anyway some potential collaboration there about the working with these data .
G	you wanna just go around ?
E	, if we if this is like everybody has something to contribute thing ,
E	there 's just couple couple people primarily
E	actually that last one said we could do fairly quickly
E	so why don't you start with that .
B	shall shall start ?
E	just explain what it was .
B	so , , he was interested in the question of , relating to his to the research he presented recently , of inference structures ,
B	and , the need to build in , , this mechanism for understanding of language .
B	and he gave the example in his talk about how ,
B	'm remembering it just off the top of my head right now ,
B	but it 's something about how , " joe slipped " , " john had washed the floor " like that .
B	and don't have it quite right ,
B	but that thing ,
B	where you have to draw the inference that , , there 's this time sequence ,
B	but also the the causal aspects of the floor and how it might have been the of the fall
B	and that it was the other person who fell than the one who cleaned it
B	and it these sorts of things .
B	so , looked through the transcript that we have so far , and , fou identified couple different types of things of that type
B	and , one of them was something like , during the course of the transcript , , we had gone through the part where everyone said which channel they were on and which device they were on ,
B	and , the question was raised " , should we restart the recording at this point ? "
B	and and dan ellis said , " , we 're just so far ahead of the game right now we really don't need to " .
B	now , how would you interpret that without lot of inference ?
B	so , the inferences that are involved are things like , , so , how do you interpret " ahead of the game " ?
B	so it 's the it 's what you what you int what you draw , the conclusions that you need to draw are that space is involved in recording ,
B	that , that we have enough space ,
B	and he continues , like " we 're so ahead of the game cuz now we have built - in downsampling " .
B	so you have to get the idea that , " ahead of the game " is sp speaking with respect to space limitations ,
B	that that downsampling is gaining us enough space ,
B	and that therefore we can keep the recording we 've done so far .
B	but there are lot of different things like that .
G	so , do you think his interest is in using this as data source ,
G	or training material ,
E	should maybe interject to say this started off with discussion that had with him ,
E	so we were trying to think of ways that his interests could interact with ours
E	and that if we were going to project into the future when we had lot of data , and such things might be useful for that in or before we invested too much effort into that he should , with jane 's help , look into some of the data that we 're already have
E	and see , is there anything to this ?
E	is there any point which you think that , , you could gain some advantage and some potential use for it .
E	cuz it could be that you 'd look through it and you say " , this is just the wrong task for him to pursue his "
E	and and got the impression from your mail that there was enough things like this just in the little sample that you looked at that it 's plausible at least .
B	it 's possible .
B	he was he we met and he was gonna go and , look through them more systematically
B	and then meet again .
B	so it 's , , not matter of
B	but , , it was optimistic .
E	so anyway , that 's that 's quite different thing from anything we 've talked about that , , might might come out from some of this .
C	but he can use text , .
C	he 's talking about just using text
B	that 's his major
B	mentioned several that had to do with implications drawn from intonational contours
B	and that wasn't as directly relevant to what he 's doing .
B	he 's interested in these knowledge structures ,
B	inferences that you draw from
E	he certainly could use text ,
E	but we were looking to see if there is there something in common between our interest in meetings and his interest in in this .
G	and imagine that transcripts of speech text that is speech probably has more of those than prepared writing .
G	whether it would or not , but it seems like it would .
E	probably de probably depends on what the prepared writing was .
B	don't would make that leap ,
B	because in narratives , , if you spell out everything in narrative , it can be really tedious ,
G	'm just thinking , , when you 're when you 're face to face , you have lot of backchannel
G	and so it 's just easier to do that broad inference jumping if it 's face to face .
G	so , if read that dan was saying " we 're ahead of the game " in that in that context ,
G	might not realize that he was talking about disk space as opposed to anything else .
B	had several that had to do with backchannels and this wasn't one of them .
B	this this one really does make you leap from
B	so he said , , " we 're ahead of the game , we have built - in downsampling " .
B	and the inference , if you had it written down , would be
G	it would be the same .
B	but there are others that have backchannelling ,
B	it 's just he was less interested in those .
F	've @ @ minute , several minutes ago , , like , briefly was not listening
F	and so who is " he " in this context ?
C	there 's lot of pronoun
F	so was just realizing we 've you guys have been talking about " he " for at least , , three four minutes without ever mentioning the person 's name again .
C	actually to make it worse , , morgan uses " you " and " you "
F	so this is this is gonna be big , big problem if you want to later do , , indexing , or speech understanding of any sort .
G	it 's in my notes .
C	with gaze and no identification ,
C	wrote this down .
C	actually . cuz morgan will say , " you had some ideas "
F	you just wrote this ?
C	and he never said li - he looked
G	he 's doing that intentionally ,
C	so it 's great .
C	so this is really great
C	because , because he 's looking at the per even for addressees in the conversation ,
C	bet you could pick that up in the acoustics .
C	just because your gaze is also correlated with the directionality of your voice .
E	that would be tou
G	that would be interesting .
C	so that , , to even know when
C	if you have the ms you should be able to pick up what person is looking at from their voice .
G	especially with morgan , with the way we have the microphones arranged . 'm right on axis
G	and it would be very hard to tell .
B	but you 'd have the
C	put morgan always like this
B	you 'd have fainter
B	wouldn't you get fainter reception out here ?
G	but if 'm talking like this ?
G	right now 'm looking at jane and talking ,
G	now 'm looking at chuck and talking ,
G	don't think the microphones would pick up that difference .
C	but you don't have this problem .
C	morgan is the one who does this most .
G	so if 'm talking at you , or 'm talking at you .
E	probably been affect no , th 've been affected by too many conversations where we were talking about lawyers and talking about and concerns about " gee is somebody going to say something bad ? " and so on .
E	and so so 'm 'm tending to stay away from people 's names even though
C	even though you could pick up later on , just from the acoustics who you were who you were looking at .
G	and we did mention who " he " was .
F	right , but missed it .
G	early in the conversation .
G	do sh - can say
E	no no , there 's
G	or is that just too sensitive ?
E	no no , it isn't sensitive .
E	was just was overreacting just because we 've been talking about it .
B	and , it is it is sensitive .
C	no , but that
C	it 's interesting .
B	came up with something from the human subjects people that wanted to mention .
B	it fits into the area of the mundane ,
B	but they did say
B	asked her very specifically about this clause of how , , , it says " no individuals will be identified
B	" in any publication using the data . "
B	, individuals being identified ,
B	let 's say you have snippet that says , " joe thinks such - and - such about this field , but he 's wrongheaded . "
B	now , we 're we 're gonna be careful not to have the " wrongheaded " part in there ,
B	but , let 's say we say , , " joe used to - and - so about this area , in his publication he says that but he 's changed his mind . " or whatever .
B	then the issue of being able to trace joe , because we know he 's - known in this field , and all this and tie it to the speaker , whose name was just mentioned moment ago , can be sensitive .
B	so it 's really adaptive and wise to not mention names any more than we have to
B	because if there 's slanderous aspect to it , then how much to we wanna be able to have to remove ?
E	, there 's that .
E	but also to some extent it 's just educating the human subjects people , in way ,
E	because there 's if , there 's court transcripts , there 's there 's transcripts of radio shows
E	people say people 's names all the time .
E	so it can't be bad to say people 's names .
E	it 's just that you 're right that there 's more poten if we never say anybody 's name , then there 's no chance of of slandering anybody ,
C	but , then it won't , if we if we
G	it 's not meeting .
C	we should do whatever 's natural in meeting if we weren't being recorded .
E	right , so so my behavior is probably not natural .
C	" if person "
B	my feeling on it was that it wasn't really important who said it ,
F	if you ha since you have to go over the transcripts later anyway , you could make it one of the jobs of the people who do that to mark
G	we we talked about this during the anon anonymization .
G	if we wanna go through and extract from the audio and the written every time someone says name .
G	and that our conclusion was that we didn't want to do that .
E	we really can't .
E	but actually , 'm . really would like to push finish this off .
B	no was suggesting that it 's not bad policy potentially .
B	so , we need to talk about this later .
E	di didn't intend it an policy though .
E	it was it was just unconscious , semi - conscious behavior .
E	sorta knew was doing it but it was
F	still who " he " is .
E	do don't remember who " he " is .
C	no , you have to say , you still who " he " is , with that prosody .
E	we were talking about dan at one point and we were talking about lokendra at another point .
B	depends on which one you mean .
E	and don't don't remember which part .
C	it 's ambiguous , so it 's .
G	the inference structures was lokendra .
F	but no . the inference was was lokendra .
F	that makes sense , .
C	and the downsampling must have been dan .
C	it 's an inference .
E	you could do all these inferences ,
E	would like to move it into what jose has been doing
E	because he 's actually been doing something .
E	so . right .
F	as opposed to the rest of us .
D	remind that me my first objective , in the project is to study difference parameters
D	to find good solution to detect , the overlapping zone in speech recorded .
D	but , tsk , ehhh in that way begin to study and to analyze the ehn the recorded speech the different session
D	to find and to locate and to mark the different overlapping zone .
D	and so was am transcribing the first session
D	and have found , one thousand acoustic events ,
D	besides the overlapping zones , the breaths aspiration , talk , clap ,
D	what is the different names you use to name the speech
G	don't think we 've been doing it at that level of detail .
D	do don't need to to mmm to to label the different acoustic ,
D	but prefer because would like to study if , will find , good parameters to detect overlapping
D	would like to to test these parameters with the another , acoustic events ,
D	to nnn to to find what is the ehm the false , the false hypothesis , nnn , which are produced when we use the ehm this parameter pitch , difference , feature
A	some of these that are the nonspeech overlapping events may be difficult even for humans to tell that there 's two there .
A	if it 's tapping sound , you wouldn't necessarily or , , something like that , it 'd be it might be hard to know that it was two separate events .
G	you weren't talking about just overlaps
G	you were just talking about acoustic events .
D	talk about acoustic events in general ,
G	someone starts , someone stops
D	but my objective will be to study overlapping zone .
D	? in twelve minutes found , one thousand acoustic events .
E	how many overlaps were there in it ?
E	no no , how many of them were the overlaps of speech , though ?
D	almost three hundred in one session
D	in five in forty - five minutes .
A	three hundred overlapping speech
D	alm - three hundred overlapping zone .
D	with the overlapping zone , overlapping speech what different duration .
B	so if you had an overlap involving three people , how many times was that counted ?
D	three people , two people .
D	would like to consider one people with difference noise in the background ,
E	no no , but what she 's asking is if at some particular for some particular stretch you had three people talking , instead of two , did you call that one event ?
D	consider one event for th for that for all the zone .
D	this th con consider consider an acoustic event , the overlapping zone , the period where three speaker or are talking together .
G	so let 's say me and jane are talking at the same time ,
G	and then liz starts talking also over all of us .
G	how many events would that be ?
D	so - don't understand .
G	so , two people are talking , and then third person starts talking .
G	is there an event right here ?
D	no . no no .
D	for me is the overlapping zone ,
D	because you have you have more one , more one voice , produced in in moment .
G	so if two or more people are talking .
E	so . we just wanted to understand how you 're defining it .
E	so then , in the region between since there is some continuous region , in between regions where there is only one person speaking .
E	and one contiguous region like that you 're calling an event .
E	is it are you calling the beginning or the end of it the event ,
E	or are you calling the entire length of it the event ?
D	consider the , nnn the nnn , nnn , the entirety
D	all the time there were the voice has overlapped .
D	this is the idea .
D	but don't distinguish between the numbers of speaker .
D	'm not considering the ehm , the fact of , , what did you say ?
D	at first , two talkers are , speaking ,
D	and , third person join to that .
D	for me , it 's it 's , all overlap zone , with several numbers of speakers is , the same acoustic event .
D	wi - but , without any mark between the zone of the overlapping zone with two speakers speaking together ,
D	and the zone with the three speakers .
B	that would just be one .
D	it one . one .
D	with , beginning mark and the ending mark .
D	because for me , is the is the zone with some distortion the spectral .
D	don't mind by the moment , by the moment .
G	but but you could imagine that three people talking has different spectral characteristic than two .
D	but but have to study . what will happen in general way ,
G	so . you had to start somewhere .
C	so there 's lot of overlap .
D	what will happen with the
G	that 's lot of overlap ,
E	so again , that 's that 's three hundred in forty - five minutes that are that are speakers , just speakers .
G	for forty - five minutes .
E	- . . .
E	so that 's about eight per minute .
B	but thousand events in twelve minutes , that 's
C	but that can include taps .
B	but thousand taps in eight minutes is in twelve minutes is lot .
D	con consider consider acoustic events , the silent too .
G	silence starting or silence ending
D	to bec to detect because consider acoustic event all the things are not speech .
D	in ge in in general point of view .
E	so how many of those thousand were silence ?
F	not speech not speech or too much speech .
D	too much speech .
E	so how many of those thousand were silence , silent sections ?
D	would like to do stylistic study
D	and give you with the report from the study from the the session one session .
D	and found that another thing .
D	when was look at nnn , the difference speech file ,
D	, if we use the ehm the mixed file , to transcribe , the events and the words , saw that the speech signal , collected by the this mike of this mike , are different from the mixed signal , we collected by headphone .
D	and it 's right .
D	but the problem is the following .
D	knew that the signal , would be different ,
D	but the problem is , we detected difference events in the speech file collected by that mike qui compared with the mixed file .
D	and so if when you transcribe only using the nnn the mixed file , it 's possible if you use the transcription to evaluate different system ,
D	it 's possible you in the
D	and you use the speech file collected by the fet mike , to to nnn to do the experiments with the system ,
D	its possible to evaluate , or to consider acoustic events that which you marked in the mixed file , but they don't appear in the speech signal collected by the by the mike .
G	the the reason that generated the mixed file was for ibm to do word level transcription , not speech event transcription .
D	, it 's good idea .
D	it 's good idea .
G	so agree that if someone wants to do speech event transcription , that the mixed signals here
G	if 'm tapping on the table , you it 's not gonna show up on any of the mikes , but it 's gonna show up rather loudly in the pzm .
D	so and say that , or this only because in my opinion , it 's necessary to to put the transcription on the speech file , collected by the objective signal .
D	the the signal collected by the , the real mike in the future , in the prototype to correct the initial segmentation with the real speech
E	the the far - field ,
D	you have to analyze
D	you have to process .
D	because found difference .
E	, just , just in that one ten second , or whatever it was , example that adam had that we passed on to others few months ago ,
E	there was that business where it was adam and jane were talking at the same time
E	and , in the close - talking mikes you couldn't hear the overlap , and in the distant mike you could .
E	so , it 's clear that if you wanna study if you wanna find all the places where there were overlap , it 's probably better to use distant mike .
F	that 's good .
E	on the other hand , there 's other phenomena that are going on at the same time for which it might be useful to look at the close - talking mikes ,
C	but why can't you use the combination of the close - talking mikes , time aligned ?
G	if you use the combination of the close - talking mikes , you would hear jane interrupting me ,
G	but you wouldn't hear the paper rustling .
G	and so if you 're interested in
C	if you 're interested in speakers overlapping other speakers and not the other kinds of nonspeech , that 's not problem ,
E	some of it 's masking masked .
A	were you interrupting him or was he interrupting you ?
G	although the other issue is that the mixed close - talking mikes
G	'm doing weird normalizations and things like that .
C	but it 's known .
C	the normalization you do is over the whole conversation
C	over the whole meeting .
C	so if you wanted to study people overlapping people , that 's not problem .
D	saw the nnn the
D	but have any results .
D	saw the speech file collected by the fet mike ,
D	and signal to to noise relation is low .
D	it 's low .
D	it 's very low . you would comp if we compare it with the headphone .
D	found that nnn that , ehm , pr probably ,
D	'm not by the moment ,
D	but it 's it 's probably that lot of ,
D	in the overlapping zone , on in several parts of the files where you can find , smooth speech from one talker in the in the meeting ,
D	it 's probably in that in those files you can not find you can not process
D	because it 's confused with noise .
D	and there are lot of
D	but have to study with more detail .
D	but my idea is to process only nnn , this nnn , this of speech .
D	because it 's more realistic .
D	'm not it 's good idea , but
G	it 's more realistic but it 'll it 'll be lot harder .
E	it 'd be hard , but on the other hand as you point out , if your if if your concern is to get the overlapping people 's speech , you will you will get that somewhat better .
E	are you making any use
E	you were you were working with th the data that had already been transcribed .
D	with by jane .
E	now did you make any use of that ?
E	see was wondering cuz we st we have these ten hours of other that is not yet transcribed .
D	the the transcription by jane , , want to use to nnn , to put
D	it 's reference for me .
D	but the transcription , don't 'm not interested in the in the words , transcription words , transcribed in follow in the in the in the speech file , but jane put mark at the beginning of each talker ,
D	in the in the meeting ,
D	she nnn includes information about the zone where there are there is an overlapping zone .
D	but there isn't any mark , time temporal mark , to to mmm - heh , to label the beginning and the end of the of the
E	right , so she is
D	ta 'm we need this information to
E	so the twelve you it took you twelve hours this included maybe some time where you were learning about what you wanted to do ,
E	but , it took you something like twelve hours to mark the forty - five minutes , your
E	you did forty - five minutes of
D	no , forty - five minutes is the is the session ,
D	all the session .
E	you haven't done the whole session .
D	all is the session .
E	this is just twelve minutes .
D	tw - twelve hours of work to segment and label twelve minutes from session of part of
E	so let me back up again .
E	so the when you said there were three hundred speaker overlaps ,
E	that 's in twelve minutes ?
D	consider all the all the session because count the nnn the overlappings marked by jane ,
D	in in the fin in the forty - five minutes .
E	so it 's three hundred in forty - five minutes ,
E	but you have you have time , marked twelve minute the overlaps in twelve minutes of it .
F	so , can ask can ask whether you found , , how accurate jane 's labels were as far as
G	not just the overlaps , everything .
F	did she miss some overlaps ? or did she ?
D	but , by the moment , don't compare , my temporal mark with jane , but want to do it .
D	because per perhaps have errors in the in the marks ,
D	and if compare with jane , it 's probably correct and to get more accurately transcription in the file .
G	also jane was doing word level .
G	so we weren't concerned with exactly when an overlap started and stopped .
F	right . right .
C	not only word level , but actually
F	'm expect 'm not expecting
D	no , it 's
C	you didn't need to show the exact point of interruption ,
C	you just were showing at the level of the phrase or the level of the speech spurt , or
B	, , would say time bin .
B	so my goal is to get words with reference to time bin , beginning and end point .
B	and and sometimes , , it was like you could have an overlap where someone said something in the middle ,
B	but , , it just wasn't important for our purposes to have it that disrupt that unit in order to have , , the words in the order in which they were spoken ,
B	it would have it would have been hard with the interface that we have .
B	now , my adam 's working on , on revised overlapping interface ,
D	it 's it 's good work ,
D	but we need more information .
F	expect you to find more overlaps than jane
G	always need more for
D	no , no . have to go to
F	because you 're looking at it at much more detailed level .
D	want wanted to compare the transcription .
G	but if it takes sixty to one
E	but have suggestion about that .
E	this is very , very time - consuming , and you 're finding lots of things
E	which 'm are gonna be very interesting ,
E	but in the interests of making progress , might
E	how would it affect your time if you only marked speaker overlaps ?
E	do not mark any other events ,
E	but only mark speaker
E	do you think that would speed it up quite bit ?
E	do do you think that would speed it up ?
E	speed up your your marking ?
D	nnn , don't understand very .
E	it took you long time to mark twelve minutes .
E	now , my suggestion was for the other thirty - three
D	on - only to mark only to mark overlapping zone , but
E	and my question is , if you did that , if you followed my suggestion , would it take much less time ?
E	then it 's good idea .
E	then it 's good idea , because it
D	because need lot of time to put the label or to do that .
E	, we know that there 's noise .
E	there 's there 's continual noise from fans and ,
E	and there is more impulsive noise from taps and
E	and something in between with paper rustling .
E	we know th that 's there
E	and it 's worthwhile thing to study ,
E	but it takes lot of time to mark all of these things .
E	whereas th would think that you we can study more or less as distinct phenomenon the overlapping of people talking .
E	so . then you can get the cuz you need
E	if it 's three hundred it sounds like you probably only have fifty or sixty or seventy events right now that are really
E	and and you need to have lot more than that to have any even visual sense of what 's going on , much less any reasonable statistics .
C	now , why do you need to mark speaker overlap by hand if you can infer it from the relative energy in the
G	that 's what was gonna bring up .
C	you shouldn't need to do this completely by hand ,
E	, . so let 's back up because you weren't here for an earlier conversation .
E	so the idea was that what he was going to be doing was experimenting with different measures
E	such as the increase in energy , such as the energy in the lpc residuals , such as
E	there 's bunch of things , increased energy is - is an obvious one .
C	in the far - field mike .
E	and , it 's not obvious ,
E	you could you could do the dumbest thing and get it ninety percent of the time .
E	but when you start going past that and trying to do better , it 's not obvious what combination of features is gonna give you the , the right detector .
E	so the idea is to have some ground truth first .
E	and so the the idea of the manual marking was to say " this , , it 's it 's really here " .
A	but liz is saying why not get it out of the transcripts ?
C	what is get it from the close - talking mikes .
C	or ge get first pass from those ,
E	we we we we talked about that .
C	and then go through
C	it 'd be lot faster probably to
G	that 's his ,
E	we we talked about that .
E	but so it 's bootstrapping thing and ,
E	the idea was , we thought it would be useful for him to look at the data anyway ,
E	and then whatever he could mark would be helpful ,
E	it 's question of what you bootstrap from .
E	do you bootstrap from simple measurement which is right most of the time and then you do better ,
E	or do you bootstrap from some human being looking at it and then do your simple measurements , from the close - talking mike .
E	even with the close - talking mike you 're not gonna get it right all the time .
C	that 's what wonder , because
C	or how bad it is ,
C	be , because that would be interesting
G	'm working on program to do that , and
C	especially because the bottleneck is the transcription .
C	we 've got lot more data than we have transcriptions for .
C	we have the audio data ,
C	we have the close - talking mike ,
C	so it seems like one project
C	that 's not perfect , but
C	that you can get the training data for pretty quickly is , ,
C	if you infer form the close - talking mikes where the on - off points are of speech ,
E	right , we discussed that .
C	how can we detect that from far - field ?
G	've 've written program to do that ,
G	and so but it 's it 's doing something very , very simple .
G	it just takes threshold , based on the volume ,
F	or you can set the threshold low and then weed out the false alarms by hand .
C	by hand . .
G	and then it does median filter , and then it looks for runs .
G	and , it seems to work ,
G	've 'm fiddling with the parameters , to get it to actually generate something ,
G	don't what 'm working on was getting it to form where we can import it into the user interface that we have , into transcriber .
G	and so told said it would take about day .
G	've worked on it for about half day ,
H	have to go .
G	so give me another half day and we 'll have something we can play with .
E	see , this is where we really need the meeting recorder query to be working ,
E	because we 've had these meetings and we 've had this discussion about this , and 'm remembering little bit about what we decided ,
E	but couldn't remember all of it .
E	so , it was partly that , , give somebody chance to actually look at the data and see what these are like , partly that we have some ground truth to compare against , , when he gets his thing going ,
C	it 's definitely good to have somebody look at it .
C	was just thinking as way to speed up , the amount of
E	that was that was exactly the notion that that we discussed .
B	another thing we discussed was that
C	it looks good .
C	'll be in touch .
B	was that there there was this already script believe that dan had written , that handle bleedthrough ,
B	cuz you have this close you have contamination from other people who speak loudly .
G	and haven't tried using that .
G	it would probably help the program that 'm doing to first feed it through that .
G	it 's cross - correlation filter .
G	so haven't tried that , but that if it it might be something it might be good way of cleaning it up little .
B	so , some thought of maybe having
B	having that be preprocessor and then run it through yours .
E	but but that 's refinement
B	that 's what we were discussing .
E	and we wanna see try the simple thing first ,
E	cuz you add this complex thing up afterwards that does something good yo you wanna see what the simple thing does first .
E	but , having somebody have some experience , again , with with marking it from human standpoint ,
E	we 're , don't expect jose to do it for fifty hours of speech ,
E	but we if if he could speed up what he was doing by just getting the speaker overlaps so that we had it , say , for forty - five minutes , then at least we 'd have three hundred examples of it .
E	and when adam was doing his automatic thing he could then compare to that and see what it was different .
A	did did something almost identical to this at one of my previous jobs , and it works pretty .
A	almost exactly what you described , an energy detector with median filter , you look for runs .
G	it seemed like the right thing to do .
A	, you can get , you get them pretty close .
G	that was with zero literature search .
A	and so doing that to generate these possibilities and then going through and saying yes or no on them would be quick way to do it .
G	that 's good validation .
B	is this proprietary ?
A	no . no .
G	do you have patent on it ?
A	it was when was working for the government .
E	then everybody owns it .
E	it 's the people .
B	, is this something that we could just co - opt ,
B	or is it ?
E	he 's pretty close , anyway . it 's
A	he 's it doesn't take long time .
B	thought if it was tried and true , then and he 's gone through additional levels of development .
G	although if you if you have some parameters like what 's good window size for the median filter
A	! have to remember .
A	'll think about it ,
A	and try to remember .
F	and it might be different for government people .
G	that 's alright .
E	good enough for government work , as they say .
A	di - dif different bandwidth .
G	was doing pretty short , , tenth of second , sorts of numbers .
E	, it if we want to
E	so , , maybe we should move on to other things in limited time .
B	can ask one question about his statistics ?
B	so so in the tw twelve minutes , , if we took three hundred and divided it by four , which is about the length of twelve minutes , , 'd expect like there should be seventy - five overlaps .
B	did you find more than seventy - five overlaps in that period , or ?
B	how many overlaps in your twelve minutes ?
D	onl - only transcribe only twelve minutes from the
D	but don't co don't count the overlap .
D	consider the the nnn the the three hundred is considered only you your transcription .
D	have to finish transcribing .
G	bet they 're more , because the beginning of the meeting had lot more overlaps than the middle .
G	middle or end .
G	because we 're we 're dealing with the , in the early meetings ,
G	we 're recording while we 're saying who 's talking on what microphone , and things like that ,
G	and that seems to be lot of overlap .
B	it 's an empirical question .
B	we could find that out .
B	'm 'm not that the beginning had more .
E	so so was gonna ask , about any other things that that either of you wanted to talk about ,
E	especially since andreas is leaving in five minutes ,
E	that you wanna go with .
C	can ask about the data ,
C	like very straightforward question is where we are on the amount of data and the amount of transcribed data ,
C	wanted to get feel for that
C	to be able to can be done first
C	and like how many meetings are we recording
E	right so there 's this there 's this forty - five minute piece that jane transcribed .
E	that piece was then sent to ibm so they could transcribe so we have some comparison point .
E	then there 's larger piece that 's been recorded and put on cd - rom and sent to ibm .
E	and then we .
C	how many meetings is that ?
G	what 's that ?
E	that was about ten hours , and there was about
C	ten it 's like ten meetings ?
G	something like that .
A	ten meetings that have been sent to ibm ?
G	haven't sent them yet because was having this problem with the missing files .
E	that 's right , that had those have not been sent .
A	how many total have we recorded now , altogether ?
E	we 're saying about twelve hours .
G	about twelve by now . twelve or thirteen .
C	- . and we 're recording only this meeting , like continuously
C	we 're only recording this one now ? or ?
E	no , so the that 's the biggest one , chunk so far ,
A	it was the morning one .
E	but there 's at least one meeting recorded of the natural language guys .
C	do they meet every week ,
E	and we talked to them about recording some more
E	and we 're going to ,
E	we 've started having morning meeting , today starting week or two ago , on the front - end issues ,
E	and we 're recording those ,
E	there 's network services and applications group here who 's to have their meetings recorded ,
E	and we 're gonna start recording them .
E	they 're they meet on tuesdays . we 're gonna start recording them next week .
E	so actually , we 're gonna start having pretty significant chunk
E	so , , adam 's struggling with trying to get things to be less buggy , and come up quicker when they do crash and things like that ,
E	now that the things are starting to happen .
E	so right now , , th 'd say the data is predominantly meeting meetings ,
E	but there are scattered other meetings in it and that amount is gonna grow
E	so that the meeting meetings will probably ultimately
E	if we 're if we collect fifty or sixty hours , the meeting meetings it will probably be , , twenty or thirty percent of it ,
E	not not eighty or ninety .
C	so there 's probably there 's three to four week ,
G	that 's what we 're aiming for .
C	that we 're aiming for .
C	and they 're each about an hour .
G	we 'll find out tomorrow whether we can really do this or not .
E	and th the other thing is 'm not pos
E	'm thinking as we 've been through this few times , that really
E	maybe you wanna do it once for the novelty ,
E	but if in general we wanna have meetings that we record from outside this group do the digits .
E	because it 's just an added bunch of weird .
E	and , , we we 're highly motivated .
E	the morning group is really motivated
E	cuz they 're working on connected digits ,
G	actually that 's something wanted to ask ,
G	is have bunch of scripts to help with the transcription of the digits .
G	we don't have to hand - transcribe the digits because we 're reading them and have those .
G	and so have some scripts that let you very quickly extract the sections of each utterance .
G	but haven't been ru haven't been doing that .
G	if did that , is someone gonna be working on it ?
G	is it something of interest ?
E	whoever we have working on the acoustics for the meeting recorder are gonna start with that .
G	'm 'm interested in it ,
G	don't have time to do it now .
F	was these meetings 'm someone thought of this , but these this reading of the numbers would be extremely helpful to do adaptation .
G	would really like someone to do adaptation .
G	so if we got someone interested in that , it would be great for meeting recorder .
E	one of the things wanted to do , , that talked to don about , is one of the possible things he could do or also , we could have someone else do it , is to do block echo cancellation ,
G	since it 's the same people over and over .
E	to try to get rid of some of the effects of the the far - field effects .
E	we have the party line has been that echo cancellation is not the right way to handle the situation
E	because people move around ,
E	and , if it 's if it 's not simple echo , like cross - talk echo , but it 's actually room acoustics , it 's it 's you can't really do inversion ,
E	and even echo cancellation is going to be something it may you someone may be moving enough that you are not able to adapt quickly
E	and so the tack that we 've taken is more " lets come up with feature approaches and multi - stream approaches and , that will be robust to it for the recognizer and not try to create clean signal " .
E	that 's the party line .
E	but it occurred to me few months ago that party lines are always , , dangerous .
E	it 's good to test them , actually .
E	and so we haven't had anybody try to do good serious job on echo cancellation and we should know how that can do .
E	so that 's something 'd like somebody to do at some point , just take these digits , take the far - field mike signal , and the close mike signal , and apply really good echo cancellation .
E	there was have been some talks recently by lucent on their
E	the block echo cancellation particularly appealed to me ,
E	trying and change it sample by sample , but you have some reasonable sized blocks . and , , th
A	what is the the artifact you try to you 're trying to get rid of when you do that ?
E	so it 's it you have direct
E	what 's the difference in if you were trying to construct linear filter , that would
F	'm signing off .
E	that would subtract off the parts of the signal that were the aspects of the signal that were different between the close - talk and the distant .
E	so in most echo cancellation
E	so you given that
E	so you 're trying to so you 'd there 's distance between the close and the distant mikes so there 's time delay there ,
E	and after the time delay , there 's these various reflections .
E	and if you figure out what 's the
E	there 's least squares algorithm that adjusts itself adjusts the weight so that you try to subtract essentially to subtract off different different reflections .
E	right ? so let 's take the simple case where you just had you had some some delay in satellite connection
E	and then there 's there 's an echo .
E	it comes back . and you want to adjust this filter so that it will maximally reduce the effect of this echo .
A	so that would mean like if you were listening to the data that was recorded on one of those .
A	just the raw data ,
A	you would you might hear an echo ?
A	and and then this noise cancellation would get
E	'm 'm saying that 's simplified version of what 's really happening . what 's really happening is
E	when 'm talking to you right now , you 're getting the direct sound from my speech ,
E	but you 're also getting , , the indirect sound that 's bounced around the room number of times .
E	so now , if you try to you to completely remove the effect of that is impractical for number of technical reasons ,
E	not to try to completely remove it , that is , invert the room response ,
E	but just to try to eliminate some of the effect of some of the echos .
E	number of people have done this
E	so that , say , if you 're talking to speakerphone , it makes it more like it would be , if you were talking right up to it .
E	so this is the st the straight - forward approach .
E	you say want to use this this item but want to subtract off various kinds of echos .
E	so you construct filter , and you have this filtered version of the speech gets gets subtracted off from the original speech .
E	then you try to you try to minimize the energy in some sense .
E	and so with some constraints .
A	clean up thing , that
E	it 's clean up thing . right .
E	so , echo cancelling is , , commonly done in telephony ,
E	and and it 's the obvious thing to do in this situation if you if , , you 're gonna be talking some distance from mike .
A	when , would have meetings with the folks in cambridge when was at bbn over the phone , they had some special speaker phone
A	and when they would first connect me , it would come on and we 'd hear all this noise .
A	and then it was and then it would come on and it was very clear ,
E	right . so it 's taking samples , it 's doing adaptation , it 's adjusting weights ,
E	and then it 's getting the sum .
E	so , anyway that 's that 's reasonable thing that 'd like to have somebody try
E	somebody look and and the digits would be reasonable thing to do that with .
E	that 'd be enough data plenty of data to do that with ,
E	and for that task you wouldn't care whether it was large vocabulary speech or anything .
B	is brian kingsbury 's work related to that ,
B	or is it different type of reverberation ?
E	brian 's kingsbury 's work is an example of what we did from the opposite dogma .
E	which is what was calling the " party line " , which is that doing that thing is not really what we want .
E	we want something more flexible , where people might change their position ,
E	and there might be ,
E	so the echo cancellation does not really allow for noise .
E	it 's if you have clean situation but you just have some delays ,
E	then we 'll figure out the right the right set of weights for your taps for your filter in order to produce the effect of those echos .
E	but if there 's noise , then the very signal that it 's looking at is corrupted
E	so that it 's decision about what the right , right delays are is , is right delayed signal is is incorrect .
E	and so , in noisy situation , , also in in situation that 's very reverberant with long reverberation times and really long delays , it 's it 's typically impractical .
E	so for those reasons ,
E	and also complete inversion ,
E	if you actually mentioned that it 's hard to really do the inversion of the room acoustics .
E	that 's difficult because often times the the system transfer function is such that when it 's inverted you get something that 's unstable ,
E	and so , if you do your estimate of what the system is , and then you try to invert it , you get filter that actually , , rings , and goes to infinity .
E	so it 's so there 's there 's that technical reason , and the fact that things move , and there 's air currents
E	there 's all sorts of all sorts of reasons why it 's not really practical .
E	so for all those kinds of reasons , we we , concluded we didn't want to in do inversion ,
E	and we 're even pretty skeptical of echo cancellation , which isn't really inversion ,
E	and we decided to do this approach of taking , just picking features , which were will give you more something that was more stable , in the presence of , or absence of , room reverberation ,
E	and that 's what brian was trying to do .
E	so , , let me just say couple things that was was gonna bring up .
E	let 's see . you actually already said this thing about the about the consent forms ,
E	which was that we now don't have to
E	so this was the human subjects folks who said this , or that ?
B	the , we 're gonna do revised form , .
B	but once person has signed it once , then that 's valid for certain number of meetings .
B	she wanted me to actually estimate how many meetings and put that on the consent form .
B	told her that would be little bit difficult to say .
B	so from practical standpoint , maybe we could have them do it once every ten meetings , .
B	it won't be that many people who do it that often ,
B	but just , , so long as they don't forget that they 've done it , .
E	back on the data thing ,
E	so there 's this one hour , ten hour , hundred hour thing that we have .
E	we have we have an hour that is transcribed ,
E	we have we have twelve hours that 's recorded but not transcribed ,
E	and at the rate we 're going , by the end of the semester we 'll have , , forty or fifty , if we if this really
E	do we have that much ?
C	it 's three to four per week .
E	let 's see ,
C	so that 's what , that
E	eight weeks , is
C	so that 's not lot of hours .
E	eight weeks times three hours is twenty - four , so that 's , so like thirty hours ?
C	know this sounds tough but we 've got the room set up .
C	was starting to think of some projects where you would use
C	similar to what we talked about with energy detection on the close - talking mikes .
C	there are number of interesting questions that you can ask about how interactions happen in meeting , that don't require any transcription .
C	so what are the patterns , the energy patterns over the meeting ?
C	and 'm really interested in this but we don't have whole lot of data .
C	so was thinking , , we 've got the room set up
C	and you can always think of , also for political reasons , if icsi collected , two hundred hours , that looks different than forty hours , even if we don't transcribe it ourselves ,
E	but don't think we 're gonna stop at the end of this semester .
E	so , th that if we are able to keep that up for few months , we are gonna have more like hundred hours .
C	is there are there any other meetings here that we can record , especially meetings that have some conflict in them or some deci
C	that have some more emotional aspects to them ,
G	we had some good ones earlier .
C	there 's laughter ,
C	'm talking more about strong differences of opinion meetings ,
C	maybe with manager types , or
G	it 's hard to record those .
C	to be allowed to record them ?
B	it 's also likely that people will cancel out afterwards .
B	but but wanted to raise the kpfa idea .
C	if there is , anyway .
E	was gonna mention that .
G	that 's good idea .
G	that 's that would be good match .
E	so . so , 'd mentioned to adam , and that was another thing was gonna talk , mention to them before that there 's it it oc it occurred to me that we might be able to get some additional data by talking to acquaintances in local broadcast media .
E	because , , we had talked before about the problem about using found data , that it 's just set up however they have it set up
E	and we don't have any say about it
E	and it 's typically one microphone ,
E	in , or and so it doesn't really give us the the characteristics we want .
E	and so do think we 're gonna continue recording here and record what we can .
E	but , it did occur to me that we could go to friends in broadcast media and say " hey you have this panel show , or this , this discussion show , and can you record multi - channel ? "
E	and they may be willing to record it with
C	with lapel mikes ?
E	they probably already use lapel ,
E	but they might be able to have it wouldn't be that weird for them to have another mike that was somewhat distant .
E	it wouldn't be exactly this setup , but it would be that thing ,
E	and what we were gonna get from uw , , assuming they they start recording , isn't als also is not going to be this exact setup .
C	right . no , that 'd be great ,
C	if we can get more data .
E	so , was thinking of looking into that .
E	the other thing that occurred to me after we had that discussion , , is that it 's even possible , since , many radio shows are not live , that we could invite them to have like some of their record some of their shows here .
C	or , they 're not as averse to wearing one of these head - mount
C	they 're on the radio ,
G	right , as we are .
C	so . , that 'd be fantastic
C	cuz those kinds of panels and those have interesting
C	th - that 's an side of style style that we 're not collecting here ,
C	it 'd be great .
E	and and the , the other side to it was the what which is where we were coming from 'll talk to you more about it later is that there 's there 's
E	the radio stations and television stations already have worked out presumably , related to , , legal issues and permissions and all that .
E	they already do what they do whatever they do .
E	so it 's , it 's so it 's so it 's another source .
E	so it 's something we should look into ,
E	we 'll collect what we collect here
E	hopefully they will collect more at uw also
E	and and maybe we have this other source .
E	but that it 's not unreasonable to aim at getting , , significantly in excess of hundred hours .
E	that was our goal .
E	the thing was , was hoping that we could @ @ in the under this controlled situation we could at least collect , , thirty to fifty hours .
E	and at the rate we 're going we 'll get pretty close to that this semester .
E	and if we continue to collect some next semester , we should ,
C	was mostly trying to think , " , if you start project , within say month , , how much data do you have to work with .
C	and you wanna you wanna fr freeze your data for awhile
C	and we don't have the transcripts back yet from ibm
C	do , do we now ?
E	we don't even have it for this , forty - five minutes , that was
C	so , not complaining , was just trying to think , , what kinds of projects can you do now versus six months from now
C	and they 're pretty different , because
E	so was thinking right now it 's this exploratory where you look at the data , you use some primitive measures and get feeling for what the scatter plots look like ,
C	right , right .
E	and and and meanwhile we collect , and it 's more like , three months from now , or six months from now you can you can do lot of other things .
C	cuz 'm not actually , just logistically that spend
C	don't wanna charge the time that have on the project too early , before there 's enough data to make good use of the time .
C	and that 's and especially with the student
C	this guy who seems
C	anyway , shouldn't say too much ,
C	but if someone came that was great and wanted to do some real work and they have to end by the end of this school year in the spring , how much data will have to work with , with that person .
C	and so it 's
E	so would think , exploratory things now . , three months from now
E	the transcriptions are bit of an unknown cuz we haven't gotten those back yet as far as the timing ,
E	but as far as the collection , it doesn't seem to me like , , unreasonable to say that in january , , ro roughly which is roughly three months from now , we should have at least something like , , twenty - five , thirty hours .
C	and we just about the transcription part of that ,
B	we need to that there 's possibility that the transcript will need to be adjusted afterwards ,
B	and es especially since these people won't be used to dealing with multi - channel transcriptions .
B	so that we 'll need to adjust some
B	and also if we wanna add things like , , more refined coding of overlaps , then definitely we should count on having an extra pass through .
B	wanted to ask another aspect of the data collection .
B	there 'd be no reason why person couldn't get together several , , friends ,
B	and come and argue about topic if they wanted to ,
E	if they really have something they wanna talk about as opposed to something @ @
E	what we 're trying to stay away from was artificial constructions ,
E	but if it 's real
C	'm thinking , politically
G	stage some political debates .
B	you could do this ,
C	or just if you 're if you ha if there are meetings here that happen that we can record even if we don't have them do the digits , or maybe have them do shorter digit thing like if it was , , , one string of digits , , they 'd probably be willing to do .
G	we don't have to do the digits if we don't want to .
C	then , having the data is very valuable ,
C	cuz it 's politically better for us to say we have this many hours of audio data , especially with the itr , if we put in proposal on it .
C	it 'll just look like icsi 's collected lot more audio data .
C	whether it 's transcribed or not , is another issue ,
C	but there 's there are research questions you can answer without the transcriptions , or at least that you can start to answer .
B	it seems like you could hold some meetings .
B	you and maybe adam ?
B	you you could maybe hold some additional meetings , if you wanted .
A	we 're already talking about two levels of detail in meetings .
A	one is without doing the digits or , the full - blown one is where you do the digits , and everything , and then talk about doing it without digits ,
A	what if we had another level , just to collect data , which is without the headsets and we just did the table - mounted .
C	need the close - talking mikes .
A	you do , .
G	it seems like it 's big part of this corpus is to have the close - talking mikes .
C	or at least , like , me personally ? would couldn't use that data .
B	and mari also ,
B	we had this came up when she was here .
B	that 's important .
C	so it 's great idea ,
E	by the , don't think the transcriptions are actually , in the long run , such big bottleneck .
C	and if it were true than would just do that ,
C	but it 's not that bad
C	like the room is not the bottleneck ,
C	and we have enough time in the room ,
C	it 's getting the people to come in and put on the and get the setup going .
E	the issue is just that we 're we 're blazing that path .
E	and and do you have any idea when the you 'll be able to send the ten hours to them ?
G	've been burning two ds day , which is about all do with the time have .
G	so it 'll be early next week .
E	so early next week we send it to them ,
E	and then we check with them to see if they 've got it
E	and we start , asking about the timing for it .
E	so once they get it sorted out about how they 're gonna do it , which they 're pretty along on , cuz they were able to read the files and so on .
G	who knows where they are .
A	have they ever responded to you ?
E	but , so they they have , they 're volunteering their time and they have lot of other things to do ,
G	you we can't complain .
E	but they but at any rate , they 'll once they get that sorted out , they 're they 're making cassettes there , then they 're handing it to someone who they who 's who is doing it ,
E	and it 's not going to be don't 's going to be that much more of deal for them to do thirty hours then to do one hour ,
E	it 's not going to be thirty
G	that 's probably true .
C	so it 's the amount of
E	it 's it 's just getting it going .
G	it 's pipeline , pipeline issues .
C	what about these lunch meetings
G	once the pipeline fills .
C	, if there 's any way without too much more overhead , even if we don't ship it right away to ibm even if we just collect it here for awhile , to record , two or three more meeting week ,
C	just to have the data , even if they 're not doing the digits , but they do wear the headphones ?
E	but the lunch meetings are one person getting up and
C	, the meetings where people eat their lunch downstairs ,
C	maybe they don't wanna be recorded , but
G	and we 're just chatting ?
C	just the ch the chatting .
G	we have lot of those .
C	actually actually think that 's useful data , the chatting ,
G	the problem with that is would would feel little constrained to ? , some of the meetings
C	you don't wanna do it , cuz
G	our " soccer ball " meeting ?
G	none of you were there for our soccer ball meeting .
C	alright , so 'll just throw it out there ,
C	if anyone knows of one more or two more wee meetings per week that happen at icsi , that we could record , it would be worth it .
G	that was hilarious .
E	, we should also check with mari again , because they because they were really intending , , maybe just didn't happen , but they were really intending to be duplicating this in some level .
E	so then that would double what we had .
E	and there 's lot of different meetings at uw
E	really lot more than we have here right cuz we 're not right on campus ,
A	is the , notion of recording any of chuck 's meetings dead in the water ,
A	or is that still possibility ?
E	they seem to have some problems with it . we can we can talk about that later .
E	but , again , jerry is jerry 's open
E	so , we have two speech meetings , one network meeting ,
E	jerry was open to it but
E	one of the things that is little little bit of limitation , there is think when the people are not involved in our work , we probably can't do it every week .
E	? that people are gonna feel are gonna feel little bit constrained .
E	now , it might get little better if we don't have them do the digits all the time .
E	and the then so then they can just really try to put the mikes on and then just charge in and
C	what if we give people , we cater lunch in exchange for them having their meeting here ?
B	, do think eating while you 're doing meeting is going to be increasing the noise .
B	but had another question , which is , , in principle , , know that you don't want artificial topics ,
C	alright , alright .
B	but it does seem to me that we might be able to get subjects from campus to come down and do something that wouldn't be too artificial .
B	we could political discussions , or other ,
C	no , definitely .
B	because , , there 's also this constraint . we
B	it 's like , , the goldibears goldi goldilocks ,
B	it 's like you don't want meetings that are too large , but you don't want meetings that are too small .
B	and and it just seems like maybe we could exploit the subj human subject pool , in the positive sense of the word .
A	even , coming down from campus is big thing , but what about
B	we could pay subjects .
A	or what about people in the in the building ?
C	was thinking , there 's all these other peo
A	there 's the state of california downstairs , and
G	really doubt that any of the state of california meetings would be recordable and then releasable to the general public .
G	so talked with some people at the haas business school who are who are interested in speech recognition
G	and , they hummed and hawed and said " maybe we could have meetings down here " ,
G	but then got email from them that said " no , we decided we 're not really interested and we don't wanna come down and hold meetings . "
G	so , it 's gonna be problem to get people regularly .
A	what about joachim , maybe he can
E	but but we but , , we get some scattered things from this and that .
E	and do think that maybe we can get somewhere with the with the radio .
E	have better contacts in radio than in television , but
A	you could get lot of lively discussions from those radio ones .
C	and they 're already they 're these things are already recorded ,
C	we don't have to ask them to
C	even and 'm not wh how they record it , but they must record from individual
E	no , 'm not talking about ones that are already recorded .
E	'm talking about new ones
C	why why not ?
E	because because we would be asking them to do something different .
C	we can find out .
C	know mark liberman was interested in ldc
E	right , that 's the found data idea .
E	but what 'm saying is if talk to people that know who do these th who produce these things we could ask them if they could record an extra channel , let 's say , of distant mike .
E	and routinely they would not do this .
E	so , since 'm interested in the distant mike , wanna make that there is at least that somewhere
E	but if we ask them to do that they might be intrigued enough by the idea that they might be willing to the might be able to talk them into it .
G	we 're getting towards the end of our disk space ,
G	so we should think about trying to wrap up here .
C	that 's good way to end meeting .
E	don't why don't we why why don't we turn them turn
G	leave them on for moment until turn this off , cuz that 's when it crashed last time .
B	that 's good to know .
E	turning off the microphone made it crash .
B	that 's good to know .
